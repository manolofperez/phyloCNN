{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PhyloCNN - CI_primates\n",
    "\n",
    "This notebook was modified [from (Lambert et al. 2023)](https://github.com/JakubVoz/deeptimelearning/blob/main/estimation/NN/empirical/BISSE_cnn_CDV_mae_CI_computation_Gomez2012.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 4638,
     "status": "ok",
     "timestamp": 1730645630728,
     "user": {
      "displayName": "Manolo Perez",
      "userId": "03028681885213161249"
     },
     "user_tz": 0
    },
    "id": "s6r5aRZSczyu",
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import model_from_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 2249,
     "status": "ok",
     "timestamp": 1730645632976,
     "user": {
      "displayName": "Manolo Perez",
      "userId": "03028681885213161249"
     },
     "user_tz": 0
    },
    "id": "yLMPH2Hmczyv",
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "#########loading data#########\n",
    "encoding_test = pd.read_csv('./Encoded_primates.csv', sep=\"\\t\", header=0, index_col=0).values.reshape(-1,1000,19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1730645632976,
     "user": {
      "displayName": "Manolo Perez",
      "userId": "03028681885213161249"
     },
     "user_tz": 0
    },
    "id": "lHFUWj50czyw",
    "outputId": "ae797d5e-92c1-4b5b-886e-a58e0fd7b37f",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Additional sampling probability and tree size for rescaling\n",
    "test_rescale = 4.064753  # Rescaling factor\n",
    "test_tree_size = 260  # Example tree size\n",
    "\n",
    "# Add a new column for sampling probability (0.25 for all nodes)\n",
    "samp_proba_list = np.array(0.68241469816273)\n",
    "encoding_test=np.concatenate((encoding_test,np.repeat(samp_proba_list,1000).reshape(-1,1000,1)),axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1730645632976,
     "user": {
      "displayName": "Manolo Perez",
      "userId": "03028681885213161249"
     },
     "user_tz": 0
    },
    "id": "R73Nxu1kczyx",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This function takes in the tree encodings for the empirical dataset\n",
    "# and processes it to have a uniform shape. It also pads the leaves and nodes \n",
    "# of the tree to ensure a fixed number of 500 leaves and nodes.\n",
    "\n",
    "def encode_pad_0s_rootage(enc):\n",
    "    # Create an empty list to hold padded training encodings\n",
    "    enc_pad = []\n",
    "    \n",
    "    # Iterate over each tree in the training dataset\n",
    "    for i in range(enc.shape[0]):\n",
    "        # Separate the leaves (where column 3 has value 1, which indicates leaves)\n",
    "        leaves = enc[i][enc[i,:,3] == 1]\n",
    "        # Sort leaves by their age (assumed to be in column 1)\n",
    "        leaves = leaves[np.argsort(leaves[:, 1])]\n",
    "        # Pad the leaves array with 0s until it has a maximum size of 500 leaves\n",
    "        leaves = np.pad(leaves, [(0, (500 - leaves.shape[0])), (0, 0)], mode='constant')\n",
    "\n",
    "        # Separate the nodes (where column 3 is greater than 1, indicating internal nodes)\n",
    "        nodes = enc[i][enc[i,:,3] > 1]\n",
    "        # Sort nodes by their age (assumed to be in column 1)\n",
    "        nodes = nodes[np.argsort(nodes[:, 1])]\n",
    "        # Copy the last node's value to balance the number of leaves and nodes\n",
    "        nodes = np.append(nodes, nodes[-1].reshape(1, -1), axis=0)\n",
    "        # Pad the nodes array with 0s to ensure a size of 500 nodes\n",
    "        nodes = np.pad(nodes, [(0, (500 - nodes.shape[0])), (0, 0)], mode='constant')\n",
    "        \n",
    "        # Stack the leaves and nodes arrays together along axis 2 (creating 2 channels)\n",
    "        enc_pad.append(np.stack((leaves, nodes), axis=2))\n",
    "    \n",
    "    # Convert lists to numpy arrays and return the padded training and test data\n",
    "    return np.array(enc_pad)\n",
    "\n",
    "#Change encoding to order by root age and pad with 0s\n",
    "encoding_pad_test = encode_pad_0s_rootage(encoding_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 821,
     "status": "ok",
     "timestamp": 1730196515959,
     "user": {
      "displayName": "Manolo Perez",
      "userId": "03028681885213161249"
     },
     "user_tz": 0
    },
    "id": "3TxCV_O5czyw",
    "outputId": "bb435709-0712-4c9a-aa25-fb5d98072c75",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 500, 20, 2)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoding_pad_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2830,
     "status": "ok",
     "timestamp": 1730645638014,
     "user": {
      "displayName": "Manolo Perez",
      "userId": "03028681885213161249"
     },
     "user_tz": 0
    },
    "id": "oTINCYw6czyx",
    "outputId": "e3b7dd8c-c1c3-41eb-f13a-732243787d93",
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model loaded!\n"
     ]
    }
   ],
   "source": [
    "#load the model\n",
    "from keras.models import model_from_json\n",
    "json_file = open('./Trained_Models/Trained_2Generation_BiSSE.json', 'r')\n",
    "model = json_file.read()\n",
    "json_file.close()\n",
    "estimator = model_from_json(model)\n",
    "#load weights\n",
    "estimator.load_weights('./Trained_Models/Trained_2Generation_BiSSE.h5')\n",
    "print('model loaded!')\n",
    "\n",
    "# predict values for the empirical data\n",
    "predicted_test = pd.DataFrame(estimator.predict(encoding_pad_test))\n",
    "predicted_test.columns = [\"turnover\", \"lambda1_rescaled\", \"lambda2_rescaled\", \"q01_rescaled\"]\n",
    "predicted_test['mu1_rescaled'] = predicted_test['turnover']*predicted_test['lambda1_rescaled']\n",
    "predicted_test['mu2_rescaled'] = predicted_test['turnover']*predicted_test['lambda2_rescaled']\n",
    "\n",
    "\n",
    "predicted_test['lambda1_rescaled'] = predicted_test['lambda1_rescaled']/test_rescale\n",
    "predicted_test['lambda2_rescaled'] = predicted_test['lambda2_rescaled']/test_rescale\n",
    "predicted_test['mu1_rescaled'] = predicted_test['mu1_rescaled']/test_rescale\n",
    "predicted_test['mu2_rescaled'] = predicted_test['mu2_rescaled']/test_rescale\n",
    "predicted_test['q01_rescaled'] = predicted_test['q01_rescaled']/test_rescale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 1874,
     "status": "ok",
     "timestamp": 1730645640435,
     "user": {
      "displayName": "Manolo Perez",
      "userId": "03028681885213161249"
     },
     "user_tz": 0
    },
    "id": "t4mrQJhUl1sy"
   },
   "outputs": [],
   "source": [
    "### load data sets for CI computations\n",
    "# CI_param: known parameter values (i.e. used for obtaining simulations in the training set)\n",
    "CI_param = pd.read_csv('BiSSE.csv', sep=\",\")\n",
    "# CI_predicted: predicted parameter values obtained with the training set\n",
    "CI_predicted = pd.read_csv('Predicted_BiSSE.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1730645640435,
     "user": {
      "displayName": "Manolo Perez",
      "userId": "03028681885213161249"
     },
     "user_tz": 0
    },
    "id": "LHMZP5LY6Crj"
   },
   "outputs": [],
   "source": [
    "# rescaling all values so that they correspond to trees of average branch length of 1\n",
    "CI_param['lambda1_rescaled'] = CI_param['lambda1']\n",
    "CI_param['lambda2_rescaled'] = CI_param['lambda2']\n",
    "CI_param['q01_rescaled'] = CI_param['q01']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1730645640435,
     "user": {
      "displayName": "Manolo Perez",
      "userId": "03028681885213161249"
     },
     "user_tz": 0
    },
    "id": "D-W8MKO5l1qW"
   },
   "outputs": [],
   "source": [
    "### prepare col names of output table\n",
    "# parameters for which we compute the CI\n",
    "targets = [\"turnover\", \"lambda1_rescaled\", \"lambda2_rescaled\", \"q01_rescaled\"]\n",
    "# number of neighboring simulation sets we consider to compute CI\n",
    "n_neighbors = [1000]\n",
    "# min max values for the computed CI values: set to biologically relevant boundaries (i.e. non negative values)\n",
    "min_max = {targets[0]: [0, 1000], targets[1]: [0, 1000], targets[2]: [0, 1000], targets[3]: [0, 1000]}\n",
    "# prepare col names of output table: value of lower boundrary, upper boundary and the width of CI\n",
    "add_ons_names = ['_CI_2_5', '_CI_97_5', '_CI_width']\n",
    "col = [add_on + '_' + str(n_neigh) for n_neigh in n_neighbors for add_on in add_ons_names]\n",
    "col_comp = []\n",
    "col_comp = [target + co for target in targets for co in col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1730645642358,
     "user": {
      "displayName": "Manolo Perez",
      "userId": "03028681885213161249"
     },
     "user_tz": 0
    },
    "id": "_j75z_X4l1nN"
   },
   "outputs": [],
   "source": [
    "def get_indexes_of_closest_single_factor(test_value, ci_values, n):\n",
    "    \"\"\"Returns indexes of knn for given set\n",
    "\n",
    "    :param test_value: float, value of parameter (e.g. sampling proba or tree size) on which we select given observation\n",
    "    :param ci_values: dataframe, values of these parameters in CI set\n",
    "    :param n: int, number of KNNs to find\n",
    "    :return: list, indexes of n KNNs\n",
    "    \"\"\"\n",
    "    ref = ci_values.iloc[(ci_values-test_value).abs().argsort()].index\n",
    "    return [ref[i] for i in range(n)]\n",
    "\n",
    "\n",
    "def get_indexes_of_closest(test_s, ci_s, n):\n",
    "    \"\"\"Returns indexes of knn for given set\n",
    "    :param test_s: dataframe, param set given observation\n",
    "    :param ci_s: dataframe, param sets of CI set\n",
    "    :param n: int, number of KNNs to find\n",
    "    :return: list, indexes of n KNNs\n",
    "    \"\"\"\n",
    "    ref = ci_s.iloc[(ci_s - test_s.values).pow(2).sum(axis=1).pow(0.5).argsort()].index\n",
    "    return [ref[i] for i in range(n)]\n",
    "\n",
    "\n",
    "def get_predicted_closest_single(indexes, pred_value_table, targ):\n",
    "    \"\"\" returns the absolute errors for knn\n",
    "    :param indexes: list, index of knn\n",
    "    :param pred_value_table: dataframe, predicted parameter values of CI set\n",
    "    :param targ: str, parameter name\n",
    "    :return: list of predictions for each knn\n",
    "    \"\"\"\n",
    "    # subset the real and predicted values of the closest neighbors\n",
    "    closest_pred = pred_value_table.loc[indexes, :]\n",
    "\n",
    "    # for single parameter, get the absolute difference between these\n",
    "    pred_d = list(closest_pred[targ][:])\n",
    "    return pred_d\n",
    "\n",
    "\n",
    "def get_error_closest_single(indexes, real_value_table, pred_value_table, targ):\n",
    "    \"\"\" returns the absolute errors for knn\n",
    "    :param indexes: list, index of knn\n",
    "    :param real_value_table: dataframe, real/target parameter values of CI set\n",
    "    :param pred_value_table: dataframe, predicted parameter values of CI set\n",
    "    :param targ: str, parameter name\n",
    "    :return: list of absolute error in predictions for each knn\n",
    "    \"\"\"\n",
    "    # subset the real and predicted values of the closest neighbors\n",
    "    closest_pred = pred_value_table.loc[indexes, :]\n",
    "    closest_real = real_value_table.loc[indexes, :]\n",
    "\n",
    "    # for single parameter, get the absolute difference between these\n",
    "    error_d = closest_pred[targ] - closest_real[targ]\n",
    "    return error_d\n",
    "\n",
    "\n",
    "def apply_filter(df1, df2, df3, df4, indexes):\n",
    "    return df1.loc[indexes], df2.loc[indexes], df3.loc[indexes], df4.loc[indexes]\n",
    "\n",
    "\n",
    "def load_files(arg_name, sep=\"\"):\n",
    "    \"\"\"Loads given file\n",
    "\n",
    "    :param arg_name: parser arg, pointer to the file\n",
    "    :param sep: str, eventual separator\n",
    "    :return: pd.Dataframe, loaded file\n",
    "    \"\"\"\n",
    "    with open(arg_name, 'r') as des0:\n",
    "        des_data0 = des0.read()\n",
    "    des0.close()\n",
    "\n",
    "    if sep == \"\":\n",
    "        output = pd.read_csv(io.StringIO(des_data0), index_col=0, header=None)\n",
    "    else:\n",
    "        output = pd.read_csv(io.StringIO(des_data0), index_col=0, header=None, sep=sep)\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "executionInfo": {
     "elapsed": 433,
     "status": "ok",
     "timestamp": 1730645644823,
     "user": {
      "displayName": "Manolo Perez",
      "userId": "03028681885213161249"
     },
     "user_tz": 0
    },
    "id": "b5Uc_Gi1l1k-"
   },
   "outputs": [],
   "source": [
    "### pre processing of datasets used for CI computation: extracting parameters of interest, standardizing them\n",
    "# extract helper parameters of the CI set\n",
    "# subset sampling probability:\n",
    "CI_sampling = CI_param[\"sampling_frac\"]\n",
    "# tree size:\n",
    "CI_tree_size = CI_param[\"tree_size\"]\n",
    "\n",
    "# subselect columns/parameters of interest for each table + all in the same order\n",
    "CI_param = CI_param[targets]\n",
    "predicted_test = predicted_test[targets]\n",
    "CI_predicted = CI_predicted[targets]\n",
    "\n",
    "# before computation, standardize all columns so that each parameter is on the same scale:\n",
    "scaler = StandardScaler()\n",
    "CI_param_standardized = pd.DataFrame(scaler.fit_transform(CI_param)) # fit to CI set\n",
    "predicted_test_standardized = pd.DataFrame(scaler.transform(predicted_test))\n",
    "\n",
    "# restore column names and index values\n",
    "CI_param_standardized.columns = CI_param.columns\n",
    "CI_param_standardized.index = CI_param.index\n",
    "predicted_test_standardized.columns = predicted_test.columns\n",
    "predicted_test_standardized.index = predicted_test.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 298,
     "status": "ok",
     "timestamp": 1730645651633,
     "user": {
      "displayName": "Manolo Perez",
      "userId": "03028681885213161249"
     },
     "user_tz": 0
    },
    "id": "9vCHA41Gl1hE",
    "outputId": "b51b18e0-83ef-4e33-85db-0e8c7e3e7a55"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "turnover [0.6284678970950318, 0.5060314170950317, 0.6557887570950317, 0.6819995970950317, 0.6408510570950318, 0.6223135670950317, 0.5810363370950318, 0.6499264370950317, 0.7240008670950318, 0.6401077970950317, 0.3734958770950318, 0.6313821970950317, 0.6190509970950318, 0.7456169370950317, 0.5746316970950317, 0.48753245709503173, 0.6684605370950317, 0.6876874970950317, 0.6007569670950318, 0.6346997970950318, 0.5721766470950317, 0.5711128970950318, 0.5261457970950317, 0.3949061370950318, 0.6259188370950318, 0.5727950370950318, 0.7091635970950317, 0.6439630370950318, 0.5130554770950317, 0.5988831970950318, 0.6945594970950318, 0.47889359709503176, 0.6828306970950317, 0.5886027970950318, 0.7544511270950318, 0.5840556970950317, 0.5786455970950318, 0.34343724709503176, 0.33096909709503175, 0.5544294570950318, 0.5672141970950317, 0.40184696709503176, 0.6181788470950317, 0.6999242670950317, 0.6155868970950318, 0.5434162970950317, 0.6157877370950318, 0.5608619270950318, 0.6859050970950318, 0.5087347670950317, 0.6574235970950318, 0.6476087970950317, 0.6467677370950318, 0.6474346970950318, 0.6917369270950318, 0.6403222970950319, 0.39037782709503177, 0.6667116570950317, 0.5889401970950318, 0.6952417970950318, 0.6291114970950318, 0.5985259270950317, 0.5134031370950318, 0.5811463970950317, 0.6311943970950318, 0.6113358970950318, 0.7214581570950318, 0.4298536270950318, 0.6578228970950317, 0.4403964670950318, 0.5900657270950318, 0.3610039970950318, 0.5595051970950318, 0.6401423270950318, 0.7223562670950318, 0.6475379570950317, 0.7466039970950318, 0.5699394470950317, 0.6144405470950317, 0.6500431970950317, 0.5049163470950317, 0.6719126370950317, 0.6341889970950318, 0.7282671970950317, 0.6469451470950318, 0.6505118970950318, 0.5589152270950317, 0.5769612970950319, 0.6105139970950317, 0.5453218970950318, 0.5129369570950317, 0.5702935970950317, 0.5734046970950318, 0.7628140570950318, 0.6244340970950318, 0.6392228570950318, 0.7073423970950318, 0.6289086370950318, 0.5650487970950318, 0.6728232970950317, 0.4656004570950318, 0.6589657970950318, 0.5360525770950317, 0.45301482709503177, 0.6431322970950318, 0.5922825370950318, 0.6960632270950318, 0.5945725370950318, 0.5788473570950318, 0.6234684970950317, 0.5852242470950317, 0.5668059270950317, 0.5364176970950317, 0.6707534970950318, 0.4367472970950318, 0.5912548970950318, 0.4894163670950318, 0.40152179709503183, 0.6093216970950318, 0.5908200970950318, 0.6182593970950317, 0.5705636970950317, 0.4393082470950318, 0.6815389370950318, 0.35987969709503176, 0.6496528370950317, 0.5585439970950318, 0.47758446709503183, 0.5801383570950318, 0.6586357270950318, 0.5969024370950318, 0.5844764970950317, 0.5674105370950318, 0.6261674970950318, 0.6895244370950318, 0.48865969709503176, 0.6270958570950317, 0.3648487270950318, 0.6700051570950317, 0.34291605709503176, 0.6645146970950319, 0.6932083370950317, 0.6053133470950318, 0.6043373970950318, 0.6623877970950317, 0.6352415970950318, 0.6994846470950318, 0.5631951970950317, 0.5574908970950317, 0.6302841970950318, 0.4562463170950318, 0.5759997970950318, 0.5872054970950318, 0.4171039770950317, 0.6872985970950317, 0.5744510970950317, 0.7714728670950318, 0.6857250570950318, 0.6144402970950317, 0.5307123970950318, 0.6450311370950318, 0.6321784370950319, 0.6309659970950318, 0.5054673770950318, 0.6326183470950317, 0.5910036470950317, 0.5209879970950317, 0.5662956670950318, 0.5072204470950318, 0.4681161970950318, 0.5505690270950317, 0.6956944570950317, 0.4870853670950318, 0.5178815570950317, 0.5946329970950317, 0.6569243970950317, 0.4578128970950318, 0.6211825670950317, 0.6080086570950317, 0.6688722370950317, 0.5903299370950318, 0.6619299670950317, 0.4849109470950318, 0.6197819970950318, 0.49928084709503173, 0.6642922970950317, 0.6937295970950318, 0.5202710370950319, 0.6061569970950318, 0.6089242970950318, 0.6039245970950318, 0.6079926970950318, 0.36795236709503176, 0.7204641970950317, 0.26666218709503176, 0.6778352570950317, 0.5566995370950317, 0.5316226470950318, 0.7152654970950317, 0.6571466970950318, 0.6863085970950318, 0.5929881370950317, 0.5993734970950317, 0.5726210970950317, 0.6433873970950317, 0.4281399270950318, 0.6589088970950318, 0.6649428470950318, 0.6960609570950317, 0.6241732370950318, 0.5137436470950317, 0.6229311970950318, 0.6034023970950317, 0.6845981970950318, 0.5666900970950317, 0.5831387970950318, 0.7227641570950318, 0.4922444770950318, 0.6025571270950318, 0.3033289570950318, 0.6108014970950317, 0.5772810970950318, 0.40322911709503184, 0.6444708970950317, 0.6320647970950317, 0.5976483570950317, 0.6618936270950317, 0.6975889970950317, 0.5992794970950318, 0.5703582970950318, 0.5901505970950317, 0.6022989970950318, 0.5855752970950318, 0.5080133970950318, 0.2823482770950318, 0.4213202970950317, 0.4923693170950318, 0.6746682470950318, 0.38370301709503174, 0.6083077970950318, 0.5931956370950318, 0.43576501709503174, 0.4906133170950318, 0.5507968970950318, 0.6858177270950319, 0.6822824970950317, 0.6837903570950318, 0.6256740970950317, 0.4916916470950317, 0.3900647970950317, 0.6299050270950317, 0.5891762970950318, 0.7237401970950318, 0.6156198470950318, 0.6859393970950318, 0.6618301970950318, 0.6904394570950317, 0.6947692970950318, 0.38397359709503176, 0.5229250470950318, 0.6359022970950318, 0.7009321970950319, 0.6013963970950318, 0.6130977970950318, 0.6137139970950317, 0.5974924370950317, 0.5736783470950318, 0.5764930370950317, 0.47670652709503175, 0.4955338770950317, 0.5678362970950318, 0.36913734709503176, 0.5954420370950317, 0.5774828470950318, 0.6199856970950318, 0.5870255970950318, 0.5184661370950318, 0.5810757370950318, 0.49370855709503175, 0.6852902970950318, 0.4555433970950318, 0.6841265970950318, 0.5246497470950318, 0.7695944970950318, 0.5474165670950317, 0.5261389970950318, 0.38007792709503174, 0.5978268270950318, 0.6600332970950318, 0.7795227970950318, 0.5588998370950318, 0.6214056370950318, 0.47038905709503176, 0.5476169570950318, 0.44221307709503177, 0.6992320970950318, 0.6915672570950318, 0.7017310970950317, 0.5393939970950318, 0.7257322970950318, 0.5767513470950317, 0.6423309970950317, 0.5687502970950318, 0.6699160970950317, 0.5324904570950317, 0.6821445970950317, 0.6083758970950317, 0.6504376270950317, 0.5448516170950317, 0.6621856970950317, 0.7078962470950317, 0.6390741970950317, 0.5979172970950317, 0.6316017970950317, 0.6030679570950318, 0.5639863970950317, 0.5819055270950318, 0.5339159970950318, 0.4840663370950318, 0.7011382970950317, 0.5779629970950317, 0.6644000570950318, 0.6161046970950318, 0.6723803470950317, 0.4049229970950317, 0.4756768970950318, 0.4362553970950318, 0.7595223970950318, 0.6498073570950317, 0.6811595970950317, 0.32768466709503175, 0.6585680970950317, 0.6502302570950318, 0.6878257970950318, 0.5442851670950318, 0.6434007970950318, 0.5803195970950318, 0.6340164970950318, 0.6136683370950318, 0.6737730470950317, 0.4235017570950318, 0.6252883970950317, 0.5578475370950318, 0.6954259970950317, 0.6595569670950318, 0.6788374970950317, 0.4996542470950318, 0.4504981970950318, 0.6594064970950319, 0.7327411470950318, 0.4793292770950317, 0.4530975970950317, 0.6752674970950318, 0.6359270970950318, 0.7518313670950317, 0.5940821970950317, 0.7244957570950318, 0.5849123970950318, 0.6150840570950318, 0.7271197570950317, 0.4830282470950317, 0.6000282370950317, 0.42761272709503173, 0.5808797470950318, 0.5820196970950318, 0.6606383470950318, 0.6648656670950318, 0.6461934970950318, 0.6067460970950317, 0.6473184970950318, 0.6941072970950317, 0.7055441370950317, 0.6474226470950317, 0.4872019570950317, 0.7147791270950318, 0.5512030770950318, 0.6329557970950317, 0.48178913709503174, 0.7018149970950317, 0.6655253970950318, 0.6515837970950318, 0.6066658970950317, 0.7181936970950318, 0.7045606970950318, 0.6658511970950318, 0.5902175970950317, 0.7121065270950317, 0.6383639970950318, 0.5490653470950319, 0.4404891570950318, 0.7266759970950317, 0.6455540470950318, 0.6374035670950318, 0.6109008970950317, 0.4299533970950318, 0.6208356970950318, 0.5319902170950318, 0.5528088970950318, 0.5200932270950318, 0.39146237709503173, 0.6721946470950317, 0.6699956570950318, 0.5674510970950317, 0.6005715970950318, 0.6378092970950319, 0.5688404470950318, 0.47530164709503175, 0.48988094709503177, 0.6478372970950317, 0.7332898470950318, 0.5563575270950318, 0.6803563970950317, 0.7151491970950317, 0.6900981570950318, 0.5905653670950318, 0.5755264970950318, 0.6697075970950318, 0.5520321270950318, 0.5873870970950318, 0.4976366970950318, 0.7138323970950318, 0.6806973970950317, 0.6574701370950318, 0.6764394970950317, 0.5936804570950318, 0.6345147970950318, 0.6331637970950318, 0.6752559970950318, 0.4342066970950318, 0.6427886970950318, 0.43438015709503175, 0.3163855770950318, 0.6372395570950318, 0.7180158970950317, 0.6090839970950318, 0.7294565570950318, 0.6035876970950318, 0.3772152970950317, 0.6119922970950318, 0.4652673170950318, 0.47379269709503175, 0.6366384970950317, 0.5489156170950318, 0.7330314970950318, 0.5920377970950317, 0.6365019970950317, 0.7164787970950318, 0.6132413570950318, 0.4824692970950317, 0.4733727970950317, 0.6707972970950318, 0.6304429970950318, 0.5195194570950318, 0.7762262970950318, 0.6002725970950318, 0.5853321970950318, 0.7411966970950318, 0.6092481970950318, 0.6978988970950317, 0.5525696970950318, 0.7238351970950317, 0.7141079670950318, 0.6516150970950317, 0.7301494970950317, 0.5808526470950318, 0.6488657970950318, 0.5230000370950318, 0.5696631270950316, 0.6965832970950318, 0.6683223670950318, 0.5095907670950317, 0.5069768570950318, 0.46721909709503173, 0.46855107709503174, 0.7337075970950317, 0.5551156670950317, 0.5926935970950317, 0.6635978970950317, 0.6943723970950317, 0.4762558970950318, 0.3570589170950318, 0.6142176370950317, 0.4443607170950318, 0.5979685970950318, 0.41574555709503175, 0.6224156970950318, 0.6357158470950318, 0.6916839270950318, 0.4999599970950318, 0.6204698970950318, 0.6717943970950317, 0.6825426970950318, 0.6303895970950318, 0.5464772270950318, 0.6993172970950318, 0.6406549970950318, 0.5036746770950318, 0.7100705970950317, 0.6532929970950317, 0.5082622470950318, 0.7041382670950317, 0.6582227970950317, 0.6750903470950317, 0.6449524970950317, 0.6856113970950317, 0.6503726370950318, 0.6162803370950317, 0.5529725170950317, 0.5292206670950318, 0.5318443970950317, 0.6135995970950318, 0.6448243970950317, 0.6081021270950318, 0.6368704570950318, 0.6585191570950317, 0.6688524570950317, 0.7531753970950318, 0.6282199970950318, 0.6835548970950317, 0.7572447970950318, 0.7184758970950318, 0.6122903470950317, 0.6588902970950318, 0.5774099970950318, 0.6238315970950318, 0.6281315570950317, 0.6358667970950317, 0.6393402270950318, 0.7400491470950318, 0.7260641570950317, 0.6255456970950318, 0.5583810970950317, 0.4723859970950317, 0.6265818470950318, 0.6052455570950317, 0.5817791970950317, 0.6487615970950318, 0.7132186970950317, 0.5542461670950318, 0.6231179370950318, 0.7208239970950318, 0.5231097270950318, 0.5666779270950317, 0.3810226970950318, 0.5053925370950318, 0.45099622709503173, 0.5820458470950317, 0.5622592370950317, 0.5907888970950318, 0.7034815970950318, 0.6421286570950318, 0.6270215970950318, 0.5618558970950318, 0.6359487970950318, 0.6543592670950318, 0.5772462970950317, 0.5461439470950318, 0.6010504270950318, 0.43938361709503176, 0.6248261470950317, 0.6103712370950318, 0.6249316970950318, 0.6976107470950318, 0.7372721970950318, 0.5610840470950318, 0.5745136970950318, 0.6296555970950317, 0.6594719370950317, 0.5301450470950317, 0.6263091470950317, 0.4935697370950318, 0.6221393970950317, 0.5964665370950318, 0.7356966570950318, 0.6477977370950317, 0.7635929370950317, 0.6040345370950317, 0.6407710270950318, 0.6736029970950318, 0.6096826470950317, 0.6416568570950317, 0.5753700170950318, 0.6905541270950317, 0.5490024970950318, 0.6276715970950317, 0.5656264970950318, 0.7990459370950318, 0.7139783970950317, 0.5801642970950317, 0.5687219970950317, 0.6810359370950317, 0.4594899970950318, 0.5464874970950317, 0.6179936370950317, 0.5053195170950318, 0.5610343970950318, 0.6529751970950318, 0.6020223570950317, 0.6090015970950318, 0.6253698970950318, 0.4129463970950318, 0.5870556970950317, 0.6639406970950318, 0.5619728270950317, 0.6073073570950318, 0.6129966970950318, 0.5836805670950318, 0.5940102970950318, 0.6121642970950318, 0.5659872370950317, 0.6793098370950318, 0.5462885970950317, 0.49175986709503183, 0.5739840270950318, 0.5645055470950318, 0.5466255670950317, 0.5185338570950317, 0.5005214770950318, 0.5905327970950318, 0.6887448970950317, 0.6331653270950317, 0.6724520470950318, 0.5044142470950317, 0.6663085370950318, 0.5443172370950318, 0.6267041970950317, 0.5506542570950317, 0.6583727970950318, 0.6619146970950317, 0.7249839370950317, 0.7098267970950318, 0.6892066370950318, 0.49362809709503175, 0.6111857970950317, 0.6497198370950317, 0.5208338170950317, 0.6216052970950318, 0.6192170970950318, 0.5515915970950318, 0.6371494670950317, 0.5635544770950318, 0.5385736970950318, 0.5930841970950318, 0.5828971970950318, 0.49054699709503174, 0.7005688970950318, 0.5183159570950318, 0.5565108970950318, 0.5938224370950318, 0.5262481670950316, 0.3548442970950318, 0.4216871570950318, 0.7069374570950318, 0.6874632470950317, 0.7352460370950318, 0.6289579370950318, 0.45126635709503177, 0.5715729370950318, 0.6194282970950318, 0.6068221970950318, 0.5970715970950318, 0.6394780970950318, 0.6630444970950318, 0.5548416470950317, 0.6052569570950317, 0.6385963970950318, 0.6528252970950318, 0.6147417670950318, 0.5950403970950318, 0.6601235470950317, 0.5146093970950317, 0.5187255070950318, 0.4849219970950318, 0.6049166470950318, 0.4612556570950318, 0.5133413470950317, 0.6236470570950318, 0.5568836970950318, 0.6561530570950318, 0.6050703170950318, 0.6583865970950318, 0.5507524470950318, 0.6434121970950318, 0.5254814570950318, 0.6185974970950318, 0.5722464770950317, 0.6678784970950318, 0.6980609970950317, 0.6266412270950318, 0.5190448370950318, 0.6464953270950318, 0.5645137370950318, 0.6563477670950318, 0.5236444770950317, 0.6603314970950318, 0.6379861970950318, 0.6881207970950317, 0.5045201370950319, 0.5027285470950318, 0.6703924970950317, 0.6004076170950319, 0.7088676370950318, 0.6471242370950318, 0.6177659670950317, 0.6694759970950317, 0.5401062570950318, 0.5600651970950318, 0.6201807670950318, 0.39202825709503175, 0.38396024709503174, 0.6431644970950318, 0.6754531970950318, 0.6229705970950318, 0.5629672470950318, 0.6732432970950317, 0.6146859470950318, 0.5313028370950318, 0.5382779670950317, 0.6068212970950317, 0.5522694970950317, 0.6382087970950318, 0.48589134709503173, 0.6706490970950318, 0.6361650370950317, 0.6227513970950317, 0.6725900270950318, 0.6050454270950318, 0.5984530370950318, 0.6711669670950318, 0.5983977670950318, 0.6946492570950318, 0.6723612970950318, 0.5876577970950317, 0.6555703970950317, 0.6358242470950317, 0.49916299709503176, 0.41300353709503174, 0.5637904970950318, 0.5731762370950317, 0.5761118970950317, 0.6547386970950317, 0.6457703370950317, 0.5478927970950317, 0.5719105970950317, 0.7484268970950317, 0.6688310570950318, 0.6546455970950317, 0.5969890570950318, 0.6402149970950317, 0.5422010670950317, 0.6543112970950318, 0.5342431670950318, 0.6109467970950317, 0.6201653970950317, 0.5984254470950318, 0.6877001470950318, 0.6185968270950317, 0.5294764970950319, 0.6051771970950317, 0.6104492970950317, 0.6132282170950318, 0.4496559570950318, 0.6226061970950318, 0.6404617970950317, 0.5902379370950317, 0.7063673570950317, 0.6219508670950318, 0.5439119970950317, 0.6197159370950318, 0.6432871470950318, 0.6021428570950318, 0.6001377770950318, 0.6295338970950317, 0.6396623970950318, 0.6074948670950318, 0.6625434970950317, 0.6376445570950318, 0.6046462770950318, 0.6529690970950318, 0.5624336470950317, 0.7716632970950318, 0.6251743970950318, 0.6350032970950318, 0.6715486970950317, 0.5989818270950318, 0.7002789970950318, 0.5759216970950318, 0.6450716570950318, 0.5141982970950318, 0.6505863970950319, 0.6108888370950317, 0.5831208270950318, 0.5857909670950318, 0.5776913370950318, 0.4697853370950318, 0.5984152270950318, 0.5989064970950317, 0.6520399570950318, 0.6018307970950317, 0.5461344570950317, 0.6026237270950318, 0.6268893370950317, 0.5459800970950318, 0.5728784970950318, 0.6702564970950318, 0.5804276970950317, 0.5827738170950317, 0.6749435970950317, 0.6198601670950318, 0.7238387370950318, 0.5621566470950318, 0.6314389470950318, 0.6608477970950318, 0.4376584970950318, 0.5733296970950317, 0.5468215970950318, 0.6182286970950318, 0.6055689970950319, 0.6076612170950317, 0.5724602370950317, 0.7045053970950318, 0.5351812570950317, 0.39331144709503174, 0.6427766970950317, 0.5384037170950318, 0.6087962970950318, 0.5866479370950317, 0.5045783570950317, 0.6839677970950317, 0.6093224570950317, 0.5342861770950318, 0.5713668970950319, 0.6268162970950318, 0.6219373970950317, 0.4999679570950318, 0.5607974470950318, 0.6095699470950318, 0.6387818970950317, 0.5515972770950317, 0.5983355970950317, 0.6287415570950318, 0.5752979670950318, 0.6915995970950317, 0.5726770970950318, 0.7548676970950318, 0.7087001970950317, 0.5492970270950317, 0.6421234470950318, 0.6265848970950317, 0.5819571370950317, 0.7235463370950318, 0.5766308970950318, 0.5445094470950317, 0.6378484970950318, 0.7002095470950318, 0.44918851709503177, 0.6168409270950318, 0.6319637970950317, 0.6330049970950317, 0.6687665370950318, 0.6625520970950318, 0.5783308970950318, 0.7310071970950317, 0.5054222170950318, 0.5925859970950317, 0.6116342970950318, 0.6807161970950317, 0.6913721970950317, 0.6560047370950318, 0.5244994270950318, 0.6710422970950317, 0.6911523470950317, 0.6502857970950318, 0.5987269570950318, 0.6208659270950317, 0.5899260970950317, 0.5667223670950318, 0.5900723370950317, 0.6037994970950318, 0.5508021970950318, 0.5423917670950318, 0.5655162670950318, 0.6464136970950317, 0.6291320570950317, 0.6296272970950317, 0.7186138470950317, 0.5916026970950318, 0.6840598470950318, 0.5832258970950317, 0.6235249270950318, 0.6511405570950317, 0.6379643770950317, 0.6536237570950318, 0.6600456970950318, 0.5997245670950317, 0.5955173570950317, 0.5754052370950318, 0.5834505970950318, 0.5483944970950317, 0.7289206970950317, 0.5344525370950318, 0.6653483970950318, 0.6470128970950317, 0.6350044570950317, 0.5583147570950318, 0.5793772970950317, 0.5553648670950317, 0.5019741970950318, 0.6711340270950318, 0.5785081970950318, 0.5069907470950318, 0.7058862270950317, 0.5535022170950318, 0.6848566970950318, 0.4822799970950318, 0.6072769370950317, 0.6174693970950318, 0.6762269970950318, 0.5874022970950318, 0.5571144970950317, 0.6068410970950318, 0.6372261570950317, 0.5619537270950318, 0.5796383670950317, 0.5997410270950317, 0.6860212970950318, 0.5429341770950318, 0.6711379370950318, 0.6173826770950317, 0.6104333570950318, 0.6358656970950318, 0.6657562970950318, 0.5705898570950317, 0.6690811970950318, 0.6245821970950317, 0.6065012970950318, 0.6508973470950318, 0.4959787970950318, 0.5207618570950318, 0.6320753970950317, 0.5460479970950317, 0.5554408470950318, 0.5179623970950318, 0.6497723970950318, 0.6138335470950318, 0.6113474670950318, 0.5825479170950318, 0.5295352370950318, 0.6186858470950318, 0.6831853470950318, 0.6865909470950318, 0.6596467470950318, 0.5644530370950318, 0.5947121570950318, 0.44576711709503175, 0.7122872670950318, 0.5209530970950318, 0.6894254970950318, 0.7458761570950319, 0.6552356970950318, 0.6684197470950317, 0.6391349970950317, 0.6077889370950318, 0.5973931970950318, 0.6550342370950318, 0.6586797970950318, 0.6394579970950318, 0.5507291970950318, 0.5292713670950318, 0.5923573970950318, 0.6327946970950318, 0.6286363270950318, 0.6149416570950318, 0.5721271970950318, 0.7275569570950318, 0.6261303970950318, 0.34719099709503176, 0.7499563470950318, 0.5884139470950318, 0.3933444970950317, 0.6274697970950317, 0.6112802170950318, 0.6376789970950317, 0.5826751970950318, 0.6301539970950317, 0.6194111370950317, 0.5671824670950317, 0.6233886970950318, 0.6505142970950318, 0.6034642770950318, 0.5548008970950318, 0.7668745370950317, 0.6024244970950318, 0.4556016470950318, 0.6150822970950318, 0.6484565970950318, 0.6180654970950318, 0.5100365770950317, 0.5893759670950318, 0.5730847370950318]\n",
      "lambda1_rescaled [0.3187622466436144, 0.4555570606436144, 0.39949247464361437, 0.3990465756436144, 0.36519119864361443, 0.3756430696436144, 0.3445048746436144, 0.3250164946436144, 0.4055953386436144, 0.4082251156436144, 0.39813029064361444, 0.3699947326436144, 0.35548133264361437, 0.4410358716436144, 0.33479993464361435, 0.3340187066436144, 0.3625913256436144, 0.3588024286436144, 0.4204116546436144, 0.38216410964361436, 0.37268713264361436, 0.3537917846436144, 0.3872762286436144, 0.3878977696436144, 0.37963471264361437, 0.3318400716436144, 0.3222394556436144, 0.3614526796436144, 0.3423369436436144, 0.3725147506436144, 0.4070696656436144, 0.35116141664361444, 0.3836951186436144, 0.3367162736436144, 0.4055266336436144, 0.40322653464361435, 0.38530440564361434, 0.4223676926436144, 0.3800016496436144, 0.41987386464361437, 0.3511173696436144, 0.3759332706436144, 0.3757229296436144, 0.40662450164361436, 0.3640119356436144, 0.3486665226436144, 0.3999204926436144, 0.2812604266436144, 0.3562233676436144, 0.4185827206436144, 0.3863107416436144, 0.3982019926436144, 0.4049115136436144, 0.3508065426436144, 0.3863374606436144, 0.3553464806436144, 0.3625830456436144, 0.39103194164361443, 0.3942897776436144, 0.5244955556436144, 0.38368945464361437, 0.3131408906436144, 0.3775950196436144, 0.37499561664361436, 0.3837792876436144, 0.5441138216436143, 0.4014908106436144, 0.37641565464361443, 0.3947353136436144, 0.3434907526436144, 0.4152042936436144, 0.3982691096436144, 0.3659409436436144, 0.4071134596436144, 0.3681597786436144, 0.3352957336436144, 0.3728515046436144, 0.3958152386436144, 0.3705632546436144, 0.3445492416436144, 0.40871705964361443, 0.40845458564361437, 0.3308903816436144, 0.3883174036436144, 0.3943413726436144, 0.38905463564361437, 0.3869361826436144, 0.3890020106436144, 0.3185464796436144, 0.32356538764361437, 0.3750451616436144, 0.3838182686436144, 0.4193746116436144, 0.39020045264361436, 0.36776324664361437, 0.3483660486436144, 0.3795326156436144, 0.3258126836436144, 0.42928232364361435, 0.3722847466436144, 0.4044660766436144, 0.4324497486436144, 0.42304836364361437, 0.3676039306436144, 0.3916151736436144, 0.3722623236436144, 0.3951799526436144, 0.3688012826436144, 0.3667871776436144, 0.44662695364361443, 0.4155860116436144, 0.3782428476436144, 0.3066783376436144, 0.3805753116436144, 0.3572550406436144, 0.3706682596436144, 0.3397940026436144, 0.4056150196436144, 0.35348740364361436, 0.36837210664361436, 0.3359367436436144, 0.3899833076436144, 0.3659338216436144, 0.3737259306436144, 0.4157867766436144, 0.35127931764361436, 0.3653814086436144, 0.3866661806436144, 0.3456862656436144, 0.3775023026436144, 0.3914065876436144, 0.47434785364361437, 0.3576808316436144, 0.44554510264361435, 0.3587609916436144, 0.37978710464361437, 0.3986507416436144, 0.36417980464361444, 0.3821595336436144, 0.3627387346436144, 0.3914546616436144, 0.3938571246436144, 0.3504966536436144, 0.36276285364361444, 0.3848618896436144, 0.36225180964361436, 0.37924683764361444, 0.3570218606436144, 0.34974730064361437, 0.4085816756436144, 0.4025876406436144, 0.3834584486436144, 0.3869294116436144, 0.33592733764361443, 0.3670067206436144, 0.3840122546436144, 0.3783291406436144, 0.4151776306436144, 0.3559134096436144, 0.37082108464361435, 0.36809315464361436, 0.31303171564361437, 0.38803323764361436, 0.3544847416436144, 0.3727882516436144, 0.3670721466436144, 0.4296330656436144, 0.3947498056436144, 0.4044508036436144, 0.42955966364361436, 0.3625179886436144, 0.3314305206436144, 0.3744092336436144, 0.37068872564361444, 0.4177197266436144, 0.38524524264361437, 0.3836786226436144, 0.36477170864361436, 0.3940664286436144, 0.3385904496436144, 0.32306747864361435, 0.40221211964361436, 0.3971794506436144, 0.38321113564361436, 0.4012508976436144, 0.3817219806436144, 0.4072112406436144, 0.39756589064361436, 0.36673005664361435, 0.4052840166436144, 0.2672111776436144, 0.33596059464361444, 0.4132193416436144, 0.40029503664361443, 0.34838795664361444, 0.40434628064361444, 0.3563723226436144, 0.3747236596436144, 0.4542743676436144, 0.3469307186436144, 0.4093057256436144, 0.35214012164361436, 0.3314288776436144, 0.4075910106436144, 0.3843639956436144, 0.4010694896436144, 0.3206037666436144, 0.3747793996436144, 0.4155821516436144, 0.3715536426436144, 0.3810691736436144, 0.37703742564361437, 0.48532833564361433, 0.3187463456436144, 0.3753090666436144, 0.39456871364361434, 0.4069830666436144, 0.3868051396436144, 0.3853743956436144, 0.38480195564361436, 0.3603645396436144, 0.3801740476436144, 0.4099066176436144, 0.3212419886436144, 0.3591599856436144, 0.3699009366436144, 0.3951513176436144, 0.3615578136436144, 0.38039285664361444, 0.3745761726436144, 0.3509607396436144, 0.3335216446436144, 0.3806194196436144, 0.3719304906436144, 0.3613114846436144, 0.3812171216436144, 0.3829458166436144, 0.3412427166436144, 0.4137364536436144, 0.3919997986436144, 0.3813295076436144, 0.4512024766436144, 0.3282598416436144, 0.4157170606436144, 0.35690221864361443, 0.3662773546436144, 0.4152838016436144, 0.4062164726436144, 0.3820369406436144, 0.3895863406436144, 0.38773751964361436, 0.3981583516436144, 0.3210240726436144, 0.3429041506436144, 0.3626414416436144, 0.35676483464361436, 0.3709291006436144, 0.3677972006436144, 0.43832297064361436, 0.4158259876436144, 0.3514914066436144, 0.3608915196436144, 0.36544672264361444, 0.3642445986436144, 0.4680345536436144, 0.3863520596436144, 0.3863375606436144, 0.40767019664361437, 0.3209006356436144, 0.3777878536436144, 0.4295507496436144, 0.3864197996436144, 0.39166315164361437, 0.3521233136436144, 0.38716088464361437, 0.3878219636436144, 0.3637643706436144, 0.3555124876436144, 0.41345542764361437, 0.40816284864361435, 0.3822508336436144, 0.3349219466436144, 0.3734905596436144, 0.3755829076436144, 0.4072872546436144, 0.3570316836436144, 0.38254194164361444, 0.3897415946436144, 0.3582193636436144, 0.3597928996436144, 0.35998059464361437, 0.3782140916436144, 0.3924267096436144, 0.3441813606436144, 0.36778761464361437, 0.3795104636436144, 0.3595896386436144, 0.3868530586436144, 0.3748486086436144, 0.3663343046436144, 0.4062175506436144, 0.3572220286436144, 0.4029001516436144, 0.3645243146436144, 0.3448569436436144, 0.3658532946436144, 0.3585466216436144, 0.3338015876436144, 0.4118559666436144, 0.32576908364361434, 0.3456933826436144, 0.3678574216436144, 0.3914893686436144, 0.40780798564361437, 0.36599970764361445, 0.35127935664361437, 0.36593689764361437, 0.3337975546436144, 0.3836992116436144, 0.3775145616436144, 0.3897191846436144, 0.3854212406436144, 0.39058343364361436, 0.39530444164361445, 0.37661021764361435, 0.3730444856436144, 0.3706430466436144, 0.4054004116436144, 0.36555037964361436, 0.31702496864361435, 0.4207848636436144, 0.5015134536436144, 0.35062336464361443, 0.2599043936436144, 0.3936624796436144, 0.3432901036436144, 0.3456974996436144, 0.4149617776436144, 0.4329871216436144, 0.3922556646436144, 0.3985315376436144, 0.3995010426436144, 0.4104250366436144, 0.3817241876436144, 0.3810490316436144, 0.3606304296436144, 0.3461757426436144, 0.3569770476436144, 0.39316512664361436, 0.3464713306436144, 0.3518524296436144, 0.38460136864361444, 0.36601511564361444, 0.38518986464361443, 0.3337881556436144, 0.3395903636436144, 0.4029538766436144, 0.3654662536436144, 0.3375723666436144, 0.3693790606436144, 0.3283425466436144, 0.34886863764361437, 0.36435617464361436, 0.33666023164361436, 0.3954620546436144, 0.4044665946436144, 0.3754877316436144, 0.4050330196436144, 0.3835666126436144, 0.3646032326436144, 0.3552748686436144, 0.3511329306436144, 0.3490263166436144, 0.3807185126436144, 0.38643547164361436, 0.37835428064361437, 0.3146744736436144, 0.37188595664361435, 0.3635906206436144, 0.3825603656436144, 0.34083608464361437, 0.3549450566436144, 0.41935772464361437, 0.3237681576436144, 0.39704732264361436, 0.43802661664361436, 0.36408352864361443, 0.39462385364361435, 0.41407158264361443, 0.38946734964361435, 0.37875789864361437, 0.3875364316436144, 0.3804697406436144, 0.48291644564361436, 0.3869375186436144, 0.3671333486436144, 0.3904194246436144, 0.3621168326436144, 0.39526845764361435, 0.3863582486436144, 0.35650236764361437, 0.38205345364361437, 0.40559255864361443, 0.3389463626436144, 0.3884589046436144, 0.3750679226436144, 0.3534846126436144, 0.40587431964361437, 0.3913597366436144, 0.36725270464361437, 0.3916861806436144, 0.4027666246436144, 0.3598133966436144, 0.3668488936436144, 0.3593719396436144, 0.3363678046436144, 0.3977989736436144, 0.3433099026436144, 0.37639918764361435, 0.4041465276436144, 0.3339971796436144, 0.3896071386436144, 0.36444944164361437, 0.3509510396436144, 0.3819206206436144, 0.3530851476436144, 0.40146886864361436, 0.3836553016436144, 0.3515206316436144, 0.3909424306436144, 0.3278316006436144, 0.3772671836436144, 0.3723392266436144, 0.39426903164361443, 0.3551224336436144, 0.3827189736436144, 0.5015995716436144, 0.3459492626436144, 0.34381861164361444, 0.3656788896436144, 0.3506623586436144, 0.39337822664361444, 0.40658255264361437, 0.37212112564361444, 0.3787388706436144, 0.3795636416436144, 0.3807739016436144, 0.3694953646436144, 0.3260402226436144, 0.4277656586436144, 0.3982839046436144, 0.3633676276436144, 0.42116910064361435, 0.38616107264361443, 0.40541061864361444, 0.3689501226436144, 0.3328948056436144, 0.4308580786436144, 0.3986325926436144, 0.3215709876436144, 0.3965267346436144, 0.4008327326436144, 0.3830937546436144, 0.3952065116436144, 0.3656310836436144, 0.3880920346436144, 0.4056043496436144, 0.3613661576436144, 0.3278896006436144, 0.3953536546436144, 0.37527856864361436, 0.34544411764361443, 0.3806921306436144, 0.38708166464361443, 0.3519905896436144, 0.3166753136436144, 0.3754303306436144, 0.3958813416436144, 0.28857522064361435, 0.3730886526436144, 0.3836630466436144, 0.4040135936436144, 0.36659851864361437, 0.40041959164361435, 0.3453889586436144, 0.3669226556436144, 0.3102446266436144, 0.3752482326436144, 0.38479089264361444, 0.3644448096436144, 0.3883909916436144, 0.31866153564361444, 0.3424230076436144, 0.3800322516436144, 0.3926758746436144, 0.3316711946436144, 0.3934895216436144, 0.4001118016436144, 0.3976995896436144, 0.3534372576436144, 0.3527918936436144, 0.4054792766436144, 0.3576197156436144, 0.3858456166436144, 0.3928406256436144, 0.4038562486436144, 0.3914130666436144, 0.3886204586436144, 0.3564988506436144, 0.3536559946436144, 0.4002482756436144, 0.3821672926436144, 0.3506852416436144, 0.34150012764361437, 0.3896145046436144, 0.4007712836436144, 0.3861611816436144, 0.3469133166436144, 0.4743846006436143, 0.39963926764361435, 0.4038319096436144, 0.3465040566436144, 0.39976996464361436, 0.3663907696436144, 0.3519139036436144, 0.3060765346436144, 0.3465763066436144, 0.4057448866436144, 0.36898625364361437, 0.37815769664361437, 0.3088138776436144, 0.3772210876436144, 0.3642092186436144, 0.3991244866436144, 0.34550298464361434, 0.33709482564361437, 0.38368015264361444, 0.31676407564361436, 0.38298468264361435, 0.3947106276436144, 0.30292075764361437, 0.32021545964361436, 0.4058108336436144, 0.3931960786436144, 0.3671698016436144, 0.3013420386436144, 0.3690991106436144, 0.41260005964361435, 0.3816033916436144, 0.3883011916436144, 0.33260384864361436, 0.3614574486436144, 0.4139098616436144, 0.3148266976436144, 0.3248429596436144, 0.3624024816436144, 0.37691870964361435, 0.3657346996436144, 0.4403167226436144, 0.3894918296436144, 0.3094732176436144, 0.3325399536436144, 0.4017306886436144, 0.37126654864361436, 0.4063985466436144, 0.36331564364361435, 0.3079162936436144, 0.3550355026436144, 0.36432771264361435, 0.3509678666436144, 0.3394009106436144, 0.3699844436436144, 0.40001148564361444, 0.3789535706436144, 0.3246765246436144, 0.38080924064361443, 0.3447014026436144, 0.38349644264361443, 0.3381331626436144, 0.4216949026436144, 0.3741741336436144, 0.3133153186436144, 0.4232329926436144, 0.3006504276436144, 0.35834912164361443, 0.3784350636436144, 0.3627342546436144, 0.4380563966436144, 0.3329026806436144, 0.3881718146436144, 0.4020587496436144, 0.3081945086436144, 0.40388281664361436, 0.38374698364361437, 0.36974487064361444, 0.40496310364361443, 0.3857215516436144, 0.38669808164361436, 0.3733808496436144, 0.43773704264361435, 0.3707696526436144, 0.36246181864361443, 0.4155145476436144, 0.31553707164361444, 0.4267223816436144, 0.3677472316436144, 0.37973185764361445, 0.36477621464361437, 0.37958383764361436, 0.3942744166436144, 0.3126220066436144, 0.39996500964361437, 0.4134288296436144, 0.3696249826436144, 0.3798683536436144, 0.38870374564361443, 0.3951519016436144, 0.3901964486436144, 0.3738308316436144, 0.3349638896436144, 0.3815300046436144, 0.3784452306436144, 0.25790725464361436, 0.3668104346436144, 0.3399787856436144, 0.3851176266436144, 0.3392083746436144, 0.45052906764361433, 0.3983066756436144, 0.3968504786436144, 0.3680505416436144, 0.35445870064361434, 0.4123968836436144, 0.4112235576436144, 0.5156128866436143, 0.3938089606436144, 0.36972006964361437, 0.38122411264361444, 0.3847826316436144, 0.38735864464361436, 0.3821141906436144, 0.3754261176436144, 0.4228006306436144, 0.4186104196436144, 0.3470534106436144, 0.3690160496436144, 0.4307066456436144, 0.4044037946436144, 0.3504014646436144, 0.4532123016436144, 0.3549756636436144, 0.3863933936436144, 0.3787535246436144, 0.3871090136436144, 0.3890601056436144, 0.3977162716436144, 0.40666013364361436, 0.3909603206436144, 0.3715462026436144, 0.36262483764361436, 0.3596154116436144, 0.3795844506436144, 0.36011321164361443, 0.2849529466436144, 0.3786583576436144, 0.3108514256436144, 0.3594489706436144, 0.3764330406436144, 0.4253698266436144, 0.3817092686436144, 0.3911565636436144, 0.48811963764361443, 0.3898851736436144, 0.3480623676436144, 0.3713922226436144, 0.3874560216436144, 0.36910130764361443, 0.3727119476436144, 0.4029858336436144, 0.3770201226436144, 0.3667841276436144, 0.4220279636436144, 0.3705540056436144, 0.3522104016436144, 0.3835172546436144, 0.41193004364361435, 0.3860495396436144, 0.3598265356436144, 0.38842641464361444, 0.3800342796436144, 0.3949831756436144, 0.3403792666436144, 0.3829826026436144, 0.3864329496436144, 0.3656346856436144, 0.40538474164361443, 0.3872228336436144, 0.4100044536436144, 0.3141427456436144, 0.3596096866436144, 0.3900710106436144, 0.3905996586436144, 0.3026963896436144, 0.38050976964361444, 0.3705335476436144, 0.3852512296436144, 0.4068505726436144, 0.4225297046436144, 0.3326593356436144, 0.34821186064361437, 0.3776170566436144, 0.3552355326436144, 0.37836123864361443, 0.3857904796436144, 0.3571699586436144, 0.38019804764361437, 0.3074192056436144, 0.3992889626436144, 0.37565734964361436, 0.3663061206436144, 0.3527879156436144, 0.3925098646436144, 0.4189561796436144, 0.4108520746436144, 0.4188604656436144, 0.3603389976436144, 0.39115594664361436, 0.5072159396436143, 0.3297577256436144, 0.3813962486436144, 0.36197202364361436, 0.3812950046436144, 0.3577030246436144, 0.3691232906436144, 0.37821247464361435, 0.3916633636436144, 0.40125302964361437, 0.3779561696436144, 0.3663679586436144, 0.3620189016436144, 0.39794364664361437, 0.40473409464361443, 0.3548306956436144, 0.3890989106436144, 0.3576435276436144, 0.3558128726436144, 0.3770506176436144, 0.3220845306436144, 0.3605380666436144, 0.4137363516436144, 0.3790887096436144, 0.3464814976436144, 0.3230183606436144, 0.3774038006436144, 0.4115371936436144, 0.3928524206436144, 0.39004288264361436, 0.36190751464361437, 0.3783778776436144, 0.3397266296436144, 0.39039131564361435, 0.3384930346436144, 0.34077334264361436, 0.34434858964361437, 0.4120670766436144, 0.3045660696436144, 0.3384599326436144, 0.4003175976436144, 0.3706503276436144, 0.37832795164361444, 0.3793752146436144, 0.3401944006436144, 0.3657149606436144, 0.3568183626436144, 0.4278467606436144, 0.3153160506436144, 0.3847453086436144, 0.3743881766436144, 0.3780912146436144, 0.3817396466436144, 0.3732332396436144, 0.3809445426436144, 0.3899070086436144, 0.4072343586436144, 0.3820568356436144, 0.3962539606436144, 0.3898870226436144, 0.45917998364361445, 0.3959791716436144, 0.35696018164361437, 0.3697988396436144, 0.3857058756436144, 0.3612679106436144, 0.2810099536436144, 0.3970974636436144, 0.3774970996436144, 0.4002398466436144, 0.37822076664361437, 0.3870721826436144, 0.3932031396436144, 0.3739936596436144, 0.34214948164361436, 0.37912983964361435, 0.3794653806436144, 0.4118313596436144, 0.44923802564361437, 0.40193617664361436, 0.38276405564361443, 0.3742938966436144, 0.39646869964361436, 0.4039430046436144, 0.3784600056436144, 0.3026821246436144, 0.37408835964361437, 0.35315431864361435, 0.3764530236436144, 0.3770781076436144, 0.4094530106436144, 0.3692530846436144, 0.4052212146436144, 0.3750878796436144, 0.3931694266436144, 0.3912367996436144, 0.3904253466436144, 0.3808408766436144, 0.3798585706436144, 0.3433802316436144, 0.4443847406436144, 0.3592860956436144, 0.3812630086436144, 0.3826238076436144, 0.3725828346436144, 0.3279081756436144, 0.3482247396436144, 0.4265296176436144, 0.3557974836436144, 0.3661579866436144, 0.4110854256436144, 0.3419907276436144, 0.3738342176436144, 0.40974359664361437, 0.3514124686436144, 0.4010906046436144, 0.36411155664361444, 0.3283239406436144, 0.3995836276436144, 0.4041745136436144, 0.34612012264361436, 0.4162407626436144, 0.38877958364361437, 0.5280070786436144, 0.3569428106436144, 0.4206863086436144, 0.37318532564361434, 0.3485300596436144, 0.3912859896436144, 0.34863805664361436, 0.3421835056436144, 0.3417611966436144, 0.33846711364361437, 0.42552922264361437, 0.3674498676436144, 0.3474112836436144, 0.3749114106436144, 0.3726348996436144, 0.3798992466436144, 0.3933564656436144, 0.35747710264361443, 0.37393993464361436, 0.39375590864361437, 0.39332338664361444, 0.4087175906436144, 0.3672162316436144, 0.35694088164361437, 0.35898535264361436, 0.3816556276436144, 0.32182087264361436, 0.4362372426436144, 0.3759341526436144, 0.3274929586436144, 0.3902224906436144, 0.40680691864361435, 0.43350363064361436, 0.38239134064361435, 0.3877528766436144, 0.3599691706436144, 0.3783873836436144, 0.41398335564361444, 0.4260744206436144, 0.3670842956436144, 0.3262460616436144, 0.36514787764361445, 0.3954495456436144, 0.37679005464361437, 0.4059351916436144, 0.4001417936436144, 0.3778422016436144, 0.4316452376436144, 0.3834100516436144, 0.3778483646436144, 0.3154385236436144, 0.3758513206436144, 0.3715816936436144, 0.3779417736436144, 0.3842597396436144, 0.36744691164361437, 0.3517147546436144, 0.3787466186436144, 0.3616666166436144, 0.38997904464361444, 0.3801233946436144, 0.3902545736436144, 0.41015138264361434, 0.3609840896436144, 0.3652701036436144, 0.3665465906436144, 0.34563147564361435, 0.3513771996436144, 0.3678372716436144, 0.3932923156436144, 0.33878696864361435, 0.33711655364361437, 0.3233670146436144, 0.3831843846436144, 0.3800540316436144, 0.3776237136436144, 0.4281150446436144, 0.4061279686436144, 0.3350159006436144, 0.4458460536436144, 0.3383370086436144, 0.41916197464361443, 0.3879651426436144, 0.3780299386436144, 0.3992561906436144, 0.3401313566436144, 0.3884940156436144, 0.3673485126436144, 0.3923345326436144, 0.4124734886436143, 0.3645738006436144, 0.4149841316436144, 0.3427816626436144, 0.3512312226436144, 0.39955105964361437, 0.4172561816436144, 0.42904235564361437, 0.3935726726436144, 0.3379551176436144, 0.3833298236436144, 0.3547066456436144, 0.3906838596436144, 0.38053429764361435, 0.3073790366436144, 0.40901118364361444, 0.3657703176436144, 0.3702592186436144, 0.3585254786436144, 0.4105326446436144, 0.37892457364361437, 0.3846984636436144, 0.37484431864361445, 0.3549322246436144, 0.3952096096436144, 0.3832541186436144, 0.3956493486436144, 0.4068250256436144, 0.3853335686436144, 0.3529074136436144, 0.3450364196436144, 0.36960090764361436, 0.3446020906436144, 0.3232729656436144, 0.3769515086436144, 0.3711792036436144, 0.41054926364361444, 0.3053320096436144, 0.40166486064361434, 0.40518241364361435, 0.3601772796436144, 0.3586267316436144, 0.3552766556436144, 0.28789567264361443, 0.3866621476436144, 0.3371463286436144, 0.3730626636436144, 0.3982487146436144, 0.37870193764361443, 0.3725848806436144, 0.3757841786436144, 0.39287087064361437, 0.36851998964361443, 0.2604981186436144, 0.3777784146436144, 0.3771891946436144, 0.3944085016436144, 0.3815291436436144, 0.2880863976436144, 0.42490609764361437, 0.3448936346436144]\n",
      "lambda2_rescaled [0.15212268531406065, 0.18320849931406064, 0.16652782031406063, 0.19718712831406066, 0.13484323431406064, 0.25474088331406064, 0.23711678431406066, 0.16662822331406066, 0.15510921531406066, 0.21330890331406066, 0.2862624323140606, 0.18606565931406066, 0.12259244631406063, 0.17586153431406065, 0.18288098931406066, 0.16906434831406064, 0.16606179331406065, 0.11192953231406066, 0.17057261031406065, 0.15192624231406066, 0.16106009231406065, 0.15809031331406065, 0.20578821731406066, 0.23699597331406064, 0.18660123431406064, 0.12852564431406063, 0.13317405531406065, 0.14068568631406064, 0.13441001031406066, 0.17459493231406065, 0.13065579831406066, 0.13346189631406064, 0.19733447331406065, 0.12023668931406065, 0.15388692831406064, 0.19527252831406067, 0.16351959831406065, 0.16012843231406063, 0.15540487531406066, 0.25461935531406066, 0.15418259931406064, 0.15344035231406064, 0.16362680631406065, 0.12401344931406064, 0.13117764031406065, 0.18917419531406066, 0.17655115631406065, 0.18461535231406068, 0.19213374031406064, 0.17811299531406066, 0.13170557631406066, 0.15860198431406067, 0.16095455131406067, 0.15396517131406065, 0.20894664531406065, 0.08304466831406065, 0.17805916131406063, 0.14613164731406064, 0.20736474631406066, 0.08184761531406065, 0.15851887831406064, 0.19783162231406065, 0.21605753831406066, 0.2723391363140607, 0.15453627831406064, 0.16951273331406067, 0.19441760631406063, 0.17764645731406065, 0.18432791431406068, 0.22418031131406066, 0.10584931931406066, 0.21293004731406065, 0.15209512031406067, 0.17463545531406066, 0.15882332131406063, 0.21203886931406066, 0.16494227531406064, 0.16522963731406065, 0.20042035531406066, 0.12867819231406066, 0.19417927631406065, 0.18504999231406066, 0.18044055931406067, 0.19816051831406065, 0.17003527931406065, 0.15959426331406065, 0.13488395631406064, 0.15461820831406065, 0.19442820031406066, 0.13893080731406063, 0.14629021131406064, 0.21825869131406064, 0.16888987631406063, 0.18149347431406065, 0.13197857331406065, 0.16136423431406066, 0.15536361431406065, 0.13728301231406065, 0.16662624631406064, 0.14396442131406065, 0.13457481631406065, 0.3163349333140607, 0.15157219131406063, 0.11181541431406067, 0.19349665231406063, 0.18111663231406064, 0.12504168631406065, 0.19543989031406064, 0.10630759031406065, 0.10752052431406067, 0.17907911731406065, 0.18414875631406064, 0.15386219731406067, 0.13756438331406065, 0.16257951131406065, 0.17860612331406064, 0.16071677531406064, 0.19705099931406064, 0.15935273231406066, 0.15136919131406065, 0.2698915563140607, 0.13858937631406065, 0.15167428031406063, 0.21093836131406066, 0.15928650531406066, 0.16494354931406063, 0.16461568431406065, 0.17393518731406066, 0.17236512131406065, 0.13704342331406066, 0.15276155331406066, 0.16198954731406065, 0.19195025131406065, 0.17386428731406064, 0.14087632331406064, 0.15055267131406064, 0.12500059131406066, 0.15025177831406064, 0.16803114431406063, 0.16264325531406065, 0.16001236831406063, 0.15372304031406064, 0.24875679531406064, 0.15629869631406065, 0.15851758231406066, 0.15379420431406066, 0.18703886831406066, 0.14840355731406066, 0.14173134931406065, 0.08194545831406064, 0.17745811731406064, 0.14784301131406064, 0.15343943031406065, 0.12755511031406064, 0.16313395731406066, 0.19344122231406063, 0.10900733031406065, 0.13598240531406064, 0.19478150531406066, 0.15145663131406065, 0.16574153531406066, 0.16534531531406063, 0.17310552931406065, 0.15020050631406065, 0.13734765231406065, 0.15185785431406065, 0.16036076831406065, 0.20468364431406064, 0.15852246631406067, 0.15935098831406064, 0.13490676431406065, 0.21143630831406063, 0.18431150831406062, 0.13954083931406067, 0.16573392331406067, 0.20928857631406064, 0.18234671031406063, 0.13501921031406067, 0.18463904231406064, 0.23633483331406066, 0.15155573931406063, 0.16190418231406065, 0.15313397731406064, 0.16594398631406063, 0.20913254131406064, 0.20902610331406066, 0.20226344631406065, 0.20384494631406067, 0.19155824231406066, 0.22995050631406067, 0.13178205631406067, 0.09035107831406064, 0.15861941331406063, 0.27611385131406063, 0.16947758531406065, 0.14108057531406062, 0.11217019431406067, 0.06720010031406065, 0.12005781231406065, 0.13780661731406066, 0.17542615931406064, 0.21453890931406064, 0.19616636531406065, 0.16287175231406065, 0.17959742531406064, 0.18191833231406065, 0.14356868331406067, 0.16195725931406066, 0.15786471831406065, 0.17759808231406063, 0.15538073131406066, 0.21279023231406066, 0.17346841631406063, 0.21596545331406067, 0.13122093231406065, 0.21321242431406065, 0.24552100931406065, 0.5133172343140606, 0.08670184031406064, 0.13199830831406065, 0.16528545131406064, 0.17364297431406064, 0.19500440331406066, 0.13715060631406065, 0.10897263031406063, 0.18863174831406065, 0.12247774831406066, 0.16590605431406064, 0.15743907631406065, 0.14238480631406064, 0.16553068231406065, 0.12831732731406065, 0.14662016231406066, 0.15667656931406065, 0.17364519331406064, 0.15347524831406065, 0.20609237431406066, 0.21319360231406065, 0.15818348831406065, 0.15978849931406064, 0.14463708031406064, 0.3051252143140606, 0.16825917331406065, 0.18082220531406065, 0.16707824931406062, 0.17466571931406066, 0.16745043731406065, 0.16220514331406066, 0.16355478831406065, 0.18363830831406067, 0.19788684831406064, 0.17122448731406065, 0.17055718031406064, 0.18483044331406065, 0.14950086831406065, 0.16917467631406063, 0.16449012531406065, 0.19341867731406065, 0.21088642331406063, 0.14561436531406066, 0.19342608631406064, 0.18635156631406063, 0.15543732231406066, 0.15345738931406067, 0.14883714931406064, 0.21606902031406067, 0.19797658631406065, 0.14412418331406066, 0.17758242231406066, 0.06240152431406065, 0.10716624631406063, 0.15345152931406067, 0.15968539031406065, 0.22238154831406065, 0.20411322931406065, 0.10250242031406068, 0.22299160831406065, 0.17691553031406065, 0.27989669731406064, 0.14487038131406066, 0.18100765831406065, 0.16679130531406067, 0.16675362831406065, 0.17008181531406066, 0.14324133731406066, 0.14037241331406067, 0.10641255131406066, 0.17847088131406066, 0.2759205903140607, 0.19488296731406066, 0.14129193831406064, 0.24989736531406068, 0.14903839631406066, 0.16975677631406064, 0.17548299531406064, 0.13329726931406063, 0.27647687831406065, 0.17109915431406064, 0.15521847531406063, 0.17858462631406066, 0.14706416031406067, 0.18945021231406065, 0.15389832131406064, 0.15768134431406064, 0.16154004131406066, 0.13309721331406066, 0.12521274031406068, 0.14518541231406065, 0.17547551131406064, 0.3427310903140607, 0.17497127731406065, 0.17591381031406064, 0.22405404031406065, 0.16733472131406066, 0.20511638031406065, 0.12061354131406066, 0.16169801231406064, 0.16935804531406065, 0.12814844131406067, 0.07260918831406066, 0.17540619431406065, 0.17570858831406067, 0.16847450731406063, 0.17254503231406065, 0.20696499531406065, 0.19687102931406064, 0.19518616231406063, 0.16960696931406066, 0.15954400231406063, 0.14941454831406065, 0.16274679631406064, 0.17337056331406064, 0.16367907431406065, 0.15565721431406065, 0.12385567431406064, 0.3636193873140607, 0.11435457631406065, 0.15404833931406064, 0.17395915231406064, 0.23088118831406065, 0.26623531431406067, 0.17193063231406064, 0.11652383831406066, 0.17054859531406064, 0.2555961273140607, 0.20789067031406064, 0.14756960331406063, 0.13173106631406065, 0.15612644231406064, 0.15735087331406064, 0.14974887731406064, 0.18621783131406064, 0.15672289531406067, 0.12124081531406064, 0.16814279831406065, 0.17380223031406064, 0.18078373431406064, 0.18603777131406063, 0.17438591531406064, 0.17543873831406065, 0.32391509931406065, 0.15393701731406065, 0.15451896931406064, 0.15448915231406066, 0.12468528231406065, 0.17658254231406065, 0.14223685531406066, 0.15328918831406063, 0.14346378331406065, 0.16146144331406065, 0.16725946231406064, 0.17582465831406063, 0.15567678831406065, 0.12293115031406066, 0.15153785731406064, 0.14692909231406065, 0.08910338331406067, 0.17062865831406063, 0.13800338131406067, 0.25245017531406067, 0.18574025731406066, 0.16620294231406063, 0.14536301631406065, 0.09277205731406063, 0.22036180731406063, 0.15209689931406065, 0.23484140331406064, 0.19392396831406064, 0.24812621331406068, 0.15592391331406066, 0.14286185731406065, 0.14140215531406064, 0.17849252031406065, 0.18007292531406066, 0.17002722531406064, 0.15189175631406063, 0.13664559031406068, 0.12414917331406067, 0.18409061131406065, 0.17309045831406067, 0.16811755131406064, 0.15518140831406066, 0.09995096331406064, 0.13558070431406066, 0.17444834731406067, 0.14476684031406065, 0.17152830731406066, 0.19041205731406066, 0.16481663531406066, 0.17769127831406065, 0.16491856131406066, 0.17875883631406064, 0.19223211531406065, 0.17471306931406066, 0.20310635731406065, 0.14777976231406068, 0.18175336131406064, 0.15229438331406064, 0.17607936531406063, 0.15269143431406065, 0.15866811031406064, 0.17767838631406063, 0.12926340831406066, 0.17031752031406064, 0.14854442931406067, 0.18992520631406065, 0.16073072731406066, 0.13113854831406066, 0.22563772331406065, 0.16064072731406065, 0.15452612631406065, 0.16038216231406066, 0.15315887631406064, 0.14617545031406062, 0.16141818431406063, 0.12486156931406064, 0.17296170931406063, 0.20380209131406066, 0.20437533831406066, 0.15593092631406064, 0.14734571131406066, 0.15373715731406065, 0.17098925531406065, 0.21132767631406066, 0.17445779631406066, 0.16717161731406066, 0.15721135431406066, 0.14449173331406065, 0.15649875631406066, 0.12603442131406067, 0.15381857631406065, 0.14015802131406063, 0.16276639731406065, 0.16798952531406064, 0.15303324831406065, 0.21743976031406065, 0.13149280531406066, 0.21297468031406067, 0.12294631631406067, 0.29435226531406067, 0.23791399531406063, 0.19146713631406065, 0.15463231331406063, 0.15325595331406067, 0.15566649931406065, 0.19944341031406063, 0.14778173431406066, 0.22128382731406065, 0.19929946531406065, 0.16656687231406064, 0.18953794131406065, 0.18425733231406063, 0.14140712131406066, 0.16051864431406065, 0.18110830931406063, 0.09622813231406063, 0.13703309231406066, 0.15862449331406064, 0.15045145331406068, 0.19385628431406066, 0.20021897531406066, 0.08830602531406065, 0.18037600231406065, 0.17229650431406063, 0.21722599631406064, 0.15571069431406065, 0.16580090231406064, 0.17781426431406067, 0.2246222023140607, 0.13839425331406066, 0.18552039031406065, 0.16612059731406065, 0.14971855331406067, 0.19512638631406065, 0.18018083131406065, 0.16837689931406066, 0.12017053731406066, 0.16084107931406066, 0.21097751331406064, 0.16525179331406065, 0.14868198731406065, 0.20038935431406063, 0.15642587531406066, 0.17229319931406065, 0.17173841031406065, 0.13891573031406065, 0.17022656931406066, 0.15208571131406062, 0.15616652931406066, 0.17687668131406065, 0.17258863831406066, 0.16203366031406063, 0.14532104031406068, 0.14676488831406065, 0.13308910731406065, 0.20249284131406065, 0.17951369531406064, 0.14543838131406064, 0.14226676831406065, 0.20090476431406062, 0.17440061631406065, 0.13499834131406066, 0.15763185131406066, 0.15554101031406065, 0.14873659431406064, 0.12430112131406065, 0.13795658931406066, 0.22821951931406065, 0.16298408931406064, 0.20247644531406064, 0.17830556331406067, 0.14289007331406064, 0.22532820931406067, 0.12984686231406065, 0.17867547831406064, 0.15345655831406066, 0.11859094631406064, 0.16806597031406065, 0.14290791531406066, 0.15298665231406064, 0.17794969631406066, 0.20880853231406063, 0.16658866931406066, 0.26289451631406063, 0.16699223831406065, 0.21848827031406065, 0.21384988631406066, 0.17559141031406067, 0.20796636231406063, 0.17620575131406066, 0.22127674731406063, 0.11184007731406065, 0.28962696831406065, 0.15934559131406065, 0.14788333931406064, 0.19584487031406064, 0.15988902731406063, 0.17534954031406064, 0.17250505931406065, 0.18541162731406063, 0.19804819231406065, 0.12480648831406066, 0.14865473731406065, 0.15568548331406065, 0.18266695931406066, 0.14224006431406067, 0.16705713331406064, 0.15588982831406065, 0.18338534031406065, 0.20942111631406066, 0.17369607331406064, 0.17687197031406066, 0.18814012331406066, 0.12729684431406066, 0.15137549531406064, 0.17148898431406065, 0.20200947631406066, 0.13498986031406066, 0.14222362831406066, 0.15007977631406066, 0.2988037853140607, 0.15704369331406065, 0.16253965831406067, 0.13883078731406065, 0.13535022031406066, 0.20034053831406065, 0.19233409731406065, 0.17534402831406065, 0.22840564031406063, 0.15432411131406065, 0.16627182631406065, 0.19664059231406064, 0.14242880331406066, 0.15953827731406067, 0.16615312431406065, 0.14159142831406066, 0.11959586431406066, 0.14249950431406067, 0.21536971731406065, 0.12958018731406065, 0.21668003731406063, 0.15280596031406063, 0.15727528331406065, 0.20242849731406065, 0.17099634431406066, 0.15920398831406066, 0.20457361531406065, 0.17277090731406067, 0.15742245231406066, 0.14653554431406066, 0.11244769531406065, 0.17596083731406065, 0.12905482031406065, 0.16823936231406064, 0.22239226931406064, 0.17323478131406067, 0.12484840131406066, 0.15439124931406065, 0.18977073931406066, 0.14853058331406063, 0.20036747631406066, 0.18019231431406063, 0.18565019031406066, 0.16026763731406066, 0.14534900331406064, 0.20341613531406066, 0.16265136931406066, 0.17133299831406068, 0.15914173831406067, 0.16866305631406064, 0.14196357031406065, 0.12935842831406066, 0.14517184031406066, 0.16984120531406063, 0.17079993931406065, 0.22386379731406064, 0.19403904431406063, 0.25186344031406066, 0.13197341331406065, 0.17381903831406065, 0.29804136731406067, 0.17542323431406065, 0.17756970631406063, 0.15077840631406067, 0.13860004631406064, 0.15215173531406065, 0.11966041931406066, 0.16365639331406065, 0.17199074631406067, 0.16290956131406065, 0.14327415931406065, 0.16613222131406066, 0.12911252531406064, 0.14097927131406063, 0.15559548631406064, 0.19210326231406066, 0.18065591531406067, 0.22585937031406064, 0.19359122231406065, 0.16161784431406065, 0.17373072531406064, 0.12441518131406065, 0.19296833231406066, 0.17801678131406065, 0.17618852331406065, 0.19275179231406064, 0.17509336931406064, 0.18274780631406065, 0.22704221731406066, 0.11523371531406065, 0.19268359931406065, 0.11372902531406065, 0.29397712731406067, 0.15625392831406065, 0.16603379831406065, 0.16240201031406065, 0.21145076731406065, 0.15085665131406065, 0.13821121431406064, 0.11611061131406064, 0.19331761331406067, 0.12746084931406065, 0.13429594131406067, 0.15587585531406065, 0.19480747431406065, 0.11872963631406064, 0.23458076131406067, 0.19712875931406068, 0.13782167131406067, 0.14631984731406067, 0.14830838931406065, 0.18101126531406064, 0.14950563331406067, 0.15502616631406066, 0.23835012331406064, 0.16250094331406065, 0.13990558431406064, 0.14936001231406065, 0.22249917031406066, 0.16766834931406066, 0.19532647531406067, 0.15936479831406064, 0.28258442331406064, 0.13934344731406065, 0.13171366931406067, 0.14705739331406065, 0.16431948531406065, 0.14261475531406065, 0.18014813831406065, 0.18055773831406066, 0.13919180831406064, 0.16079728731406065, 0.19763673131406065, 0.14781038931406065, 0.16529780431406066, 0.17782684931406065, 0.17290019031406065, 0.20562755631406066, 0.20414637431406066, 0.20490321631406067, 0.24199152431406065, 0.21029419231406066, 0.18553834731406066, 0.12881585631406064, 0.25328107831406066, 0.16444666031406066, 0.18019536631406066, 0.20054313631406068, 0.18052817531406065, 0.23619766631406067, 0.16518270331406065, 0.19726272931406066, 0.13733167631406065, 0.28265291631406064, 0.3149141963140606, 0.14579510531406065, 0.13543229831406065, 0.21354654831406067, 0.16751956231406065, 0.17051076731406065, 0.13397825031406066, 0.17174019331406065, 0.15205059431406065, 0.21007731031406066, 0.16363138231406066, 0.19449744331406066, 0.20098488231406064, 0.21140643531406061, 0.18232053031406065, 0.18265532031406068, 0.20152210931406064, 0.17324948831406065, 0.20859924331406066, 0.19836351931406063, 0.16806854231406065, 0.19094546931406065, 0.15394157931406066, 0.14766538631406065, 0.17711165831406064, 0.15963465331406065, 0.2677289093140607, 0.17561606731406065, 0.18694817631406066, 0.15322379131406066, 0.14434995131406064, 0.29703476631406067, 0.15477205331406066, 0.15875121731406067, 0.3041632593140607, 0.18044965831406068, 0.16406519731406066, 0.19610458231406067, 0.16627010631406064, 0.18460901231406066, 0.21729884731406066, 0.17707957931406065, 0.11528762331406064, 0.13795929231406065, 0.20295987931406065, 0.14485706231406065, 0.20620385431406066, 0.16500328231406067, 0.14647484231406066, 0.17119421831406065, 0.15443870331406065, 0.12967343931406067, 0.25529084131406066, 0.22151602231406062, 0.12377853931406063, 0.15781772531406063, 0.15062985731406067, 0.21942101731406066, 0.17659358431406064, 0.20022748531406068, 0.22398835631406067, 0.18132046331406065, 0.18807527031406066, 0.17175606431406065, 0.13568073731406063, 0.27538228631406064, 0.19663202131406066, 0.16458477231406066, 0.13671247031406067, 0.17356751231406065, 0.17671416631406064, 0.13363440031406063, 0.16492174131406065, 0.14044886531406067, 0.17942252431406067, 0.16570901431406065, 0.17441394031406066, 0.17604616031406065, 0.15332789931406066, 0.17081773731406066, 0.23552746431406066, 0.17840817331406067, 0.14169012431406067, 0.22612815731406063, 0.09001161431406063, 0.08643906131406065, 0.16536372531406066, 0.18416412731406068, 0.13893869231406067, 0.16831107631406064, 0.16253125131406063, 0.16155430831406065, 0.16991742231406065, 0.15877598131406065, 0.10433046531406065, 0.18709332131406065, 0.19295046431406065, 0.16838454531406066, 0.16983596231406065, 0.15316492731406064, 0.14404733831406066, 0.12808952731406065, 0.19524773031406065, 0.19325151531406065, 0.19888353131406064, 0.15860009431406066, 0.20174061231406065, 0.12162515331406065, 0.12751718931406064, 0.13808270931406066, 0.15152910231406064, 0.16113555631406065, 0.16454448231406066, 0.18820388531406065, 0.15633103831406067, 0.17182530131406065, 0.15570702831406066, 0.15518085631406067, 0.16403677431406066, 0.14826187231406066, 0.24080385531406065, 0.19989614231406064, 0.14933907031406063, 0.19192489831406068, 0.12606837831406065, 0.14815088931406065, 0.19202081831406068, 0.13888097931406063, 0.19791989731406065, 0.16296169231406066, 0.14784458031406067, 0.16180850031406066, 0.11563513831406065, 0.17116164931406064, 0.24430029731406064, 0.15338818231406062, 0.12318713531406064, 0.16616154031406066, 0.19379516131406066, 0.14327001531406067, 0.1912401543140607, 0.21046244431406064, 0.14758783831406064, 0.17468510231406065, 0.11786247631406066, 0.17661898631406064, 0.15787518031406067, 0.14691721431406066, 0.18012562731406065, 0.17499669431406065, 0.17004681631406066, 0.17002242731406067, 0.02100638131406063, 0.14392363831406066, 0.14746950731406067, 0.17183576731406067, 0.18396966631406067, 0.18697100331406066, 0.19967773831406066, 0.15753043331406066, 0.2541058483140607, 0.10644477031406066, 0.17413017831406066, 0.16562937831406063, 0.14808081131406065, 0.22161866931406066, 0.23042708331406064, 0.18892609231406066, 0.18426383731406065, 0.16672259531406067, 0.17228630031406067, 0.19972713531406067, 0.15773911931406065, 0.18796009131406066, 0.21874144031406065, 0.18408012131406065, 0.20034749431406065, 0.12746523031406065, 0.14482600231406065, 0.14952963231406063, 0.17560826231406065, 0.18096622431406065, 0.17743719631406066, 0.15066342231406066, 0.16858564231406065, 0.6054176853140607, 0.17771404931406065, 0.16320864631406065, 0.25196721131406064, 0.14711030731406063, 0.12812133831406067, 0.16240015131406066, 0.17588345331406066, 0.17016843831406064, 0.18926717831406067, 0.19095670231406067, 0.22939387831406063, 0.12074827131406066, 0.14874621631406065, 0.18447700431406064, 0.15062817331406067, 0.21333116531406066, 0.23393327731406063, 0.15699899431406067, 0.15144778531406064, 0.16214294831406065, 0.14506516631406066, 0.17501167331406065, 0.12537256031406063, 0.17148074131406063, 0.3102264103140607, 0.18821424331406064, 0.14601247031406067, 0.18301934831406064, 0.18179564731406064, 0.21937466231406066, 0.19944389531406065, 0.16349073831406066, 0.18693786031406065, 0.14706673031406065, 0.19614736331406069, 0.21122282131406064, 0.11323948431406064, 0.14057638031406064, 0.10895600731406063, 0.27526045231406066, 0.09299454831406065, 0.24423079431406067, 0.15307364831406067, 0.15886606931406067, 0.20900686131406065, 0.18547120331406067, 0.12684248531406064, 0.6245022993140608, 0.14085670631406066, 0.15684777931406066, 0.13399758231406064, 0.21334366631406065, 0.14693157431406065, 0.16058124731406065, 0.18259772731406065, 0.17253803631406067, 0.15615334531406067, 0.14825033231406065, 0.43932176531406064, 0.15369287331406065, 0.13987470131406066, 0.17769196131406065, 0.15744628731406066, 0.14189196931406067, 0.29235576331406066, 0.16285737731406066, 0.17259725131406065, 0.16151392431406064, 0.20130168531406067, 0.15517962031406066, 0.20461863031406066, 0.17077858831406065, 0.13957107831406065, 0.18242060931406065, 0.16971979031406065, 0.20269193731406066, 0.15871347131406066, 0.14122090531406065, 0.12077763531406066, 0.14668884331406065]\n",
      "q01_rescaled [0.014693887742597077, 0.02196861474259708, 0.012033601742597076, 0.010737094742597077, 0.010179585742597079, 0.00962143474259708, 0.014593240742597078, 0.009206351742597079, 0.008803816742597077, 0.011346136742597077, 0.012071780742597078, 0.014768828742597075, 0.008584024742597077, 0.011950439742597078, 0.009978062742597077, 0.029127027742597077, 0.011709349742597078, 0.007690692742597077, 0.00851699774259708, 0.014528507742597077, 0.01688100574259708, 0.007043090742597077, 0.011622291742597077, 0.018738873742597077, 0.012142044742597079, 0.019585444742597078, 0.012690039742597078, 0.008709823742597076, 0.013112796742597077, 0.011511555742597077, 0.006356157742597078, 0.012896268742597077, 0.01800675874259708, 0.01213353274259708, 0.012522782742597077, 0.018156196742597077, 0.011175784742597079, 0.00863565574259708, 0.030063393742597075, 0.012380095742597078, 0.018098606742597077, 0.009392070742597076, 0.0025678787425970784, 0.019029876742597075, 0.005069600742597078, 0.009177907742597077, 0.00958841774259708, 0.010258746742597077, 0.011924900742597076, 0.007456034742597077, 0.007460790742597079, 0.007774871742597078, 0.02355842974259708, 0.012850399742597076, 0.012821938742597079, 0.007433712742597079, 0.009774416742597079, 0.010770659742597076, 0.0072855327425970775, 0.009098697742597077, 0.010416887742597077, 0.00949055374259708, 0.012422085742597077, 0.007711470742597078, 0.010516246742597078, 0.013305838742597078, 0.011275109742597076, 0.012589091742597078, 0.01125317374259708, 0.016195360742597077, 0.007746204742597078, 0.009541431742597077, 0.014265403742597077, 0.009585007742597077, 0.008436732742597076, 0.013180078742597079, 0.008435308742597077, 0.008531384742597077, 0.008641142742597079, 0.007144990742597078, 0.011923840742597079, 0.014947675742597078, 0.009514979742597077, 0.009591720742597079, 0.02172010874259708, 0.016327503742597078, 0.008297065742597077, 0.010675218742597078, 0.006640386742597078, 0.009893904742597076, 0.01764676074259708, 0.01299030274259708, 0.012624044742597079, 0.008603982742597077, 0.008783731742597077, 0.007662746742597078, 0.011548926742597079, 0.00968612974259708, 0.01287588274259708, 0.009993721742597078, 0.016026476742597075, 0.013471072742597078, 0.010150838742597076, 0.013263654742597077, 0.011282684742597079, 0.0031655207425970782, 0.017468563742597077, 0.008730043742597077, 0.013204096742597076, 0.009503713742597078, 0.012973541742597076, 0.01203214474259708, 0.011914535742597078, 0.014104960742597077, 0.012173235742597079, 0.013828788742597076, 0.010278231742597076, 0.012353420742597078, 0.009728170742597079, 0.013693382742597078, 0.01592125174259708, 0.016494151742597076, 0.008911336742597076, 0.011596572742597077, 0.014982458742597078, 0.010496929742597076, 0.019030222742597077, 0.016068536742597075, 0.010385057742597077, 0.008156519742597079, 0.008865987742597076, 0.017041202742597076, 0.016110207742597075, 0.01976566574259708, 0.020198208742597076, 0.009006428742597078, 0.008403515742597078, 0.009381428742597078, 0.012290632742597077, 0.012201553742597078, 0.010484628742597077, 0.01879616874259708, 0.012753338742597077, 0.009062789742597076, 0.007944581742597077, 0.01085700674259708, 0.015129785742597077, 0.008552061742597077, 0.012036525742597077, 0.010502168742597077, 0.012119450742597078, 0.010604538742597078, 0.01301950974259708, 0.011787090742597078, 0.009881192742597078, 0.011442808742597076, 0.012775721742597078, 0.01063954274259708, 0.006760468742597077, 0.00923287474259708, 0.01910919674259708, 0.010333207742597078, 0.01244424174259708, 0.02151309674259708, 0.009717796742597078, 0.007027541742597077, 0.01838946374259708, 0.011542676742597076, 0.014244737742597078, 0.01211182074259708, 0.016623779742597076, 0.012326909742597078, 0.010886723742597079, 0.010133780742597076, 0.013832278742597078, 0.00868792074259708, 0.01839489274259708, 0.010342822742597079, 0.008279491742597078, 0.010367999742597077, 0.010177838742597079, 0.019664344742597078, 0.006189222742597078, 0.010713396742597078, 0.009702042742597079, 0.011015695742597077, 0.00893348374259708, 0.018159838742597075, 0.010922224742597079, 0.009123474742597077, 0.015721008742597076, 0.027781461742597074, 0.011990331742597077, 0.011992343742597077, 0.007522984742597078, 0.010296764742597077, 0.009316221742597077, 0.025070270742597076, 0.005997605742597077, 0.009210153742597076, 0.008787580742597077, 0.008810236742597077, 0.01130519274259708, 0.016182254742597078, 0.015500758742597077, 0.011149990742597076, 0.008712200742597077, 0.010173165742597079, 0.017307665742597077, 0.014582363742597079, 0.008306545742597076, 0.015453355742597076, 0.007672756742597078, 0.011904775742597077, 0.01949201674259708, 0.01141237674259708, 0.009267615742597077, 0.013879924742597076, 0.007910566742597078, 0.014421297742597077, 0.009078689742597078, 0.018500578742597078, 0.012218106742597077, 0.011734783742597076, 0.013484767742597076, 0.007633887742597077, 0.00861464974259708, 0.010854946742597078, 0.012309840742597077, 0.012188708742597077, 0.010397099742597078, 0.009764558742597077, 0.008450962742597077, 0.00815214774259708, 0.00976192974259708, 0.012372249742597076, 0.008984094742597079, 0.009634824742597078, 0.017518386742597078, 0.010381176742597076, 0.006098468742597078, 0.012692972742597078, 0.013491628742597076, 0.009433343742597078, 0.009632299742597078, 0.00939758874259708, 0.01014133474259708, 0.007655104742597079, 0.013075981742597078, 0.009939277742597077, 0.012887475742597077, 0.008632693742597078, 0.020700432742597075, 0.011014231742597077, 0.008992308742597079, 0.010503318742597079, 0.010215570742597078, 0.013625709742597077, 0.006968412742597078, 0.00908206874259708, 0.007294457742597077, 0.008600060742597077, 0.021653850742597076, 0.016499092742597078, 0.010019210742597078, 0.009218818742597078, 0.011427036742597079, 0.009421991742597079, 0.010857738742597076, 0.013306052742597076, 0.012841503742597078, 0.006342097742597077, 0.013025139742597079, 0.007622385742597079, 0.015250715742597079, 0.008223615742597078, 0.010232290742597079, 0.010950633742597075, 0.014921524742597076, 0.008527948742597078, 0.010492751742597079, 0.00896227674259708, 0.007338897742597078, 0.009106026742597077, 0.012977301742597078, 0.010511043742597079, 0.009280264742597077, 0.011952575742597078, 0.0038838477425970777, 0.015388200742597079, 0.02521405474259708, 0.012594214742597077, 0.007332379742597078, 0.007101371742597079, 0.02055181274259708, 0.006381648742597079, 0.018465551742597078, 0.01483259074259708, 0.0021810407425970763, 0.010242726742597078, 0.00924901074259708, 0.014034233742597078, 0.009595793742597076, 0.01033015174259708, 0.0062982277425970784, 0.010452443742597076, 0.01969440674259708, 0.01331296774259708, 0.015163045742597078, 0.02094958374259708, 0.00874157474259708, 0.020551667742597077, 0.013099040742597077, 0.007670816742597078, 0.010361722742597078, 0.012404931742597079, 0.012161144742597076, 0.015855253742597077, 0.009183031742597079, 0.014498284742597078, 0.008805907742597076, 0.013978224742597078, 0.019218942742597077, 0.010736497742597079, 0.010382670742597078, 0.011744125742597079, 0.011161824742597078, 0.009749898742597077, 0.01501853674259708, 0.011369570742597077, 0.01537258374259708, 0.01202320674259708, 0.01297282974259708, 0.011581091742597076, 0.007602914742597077, 0.01530251774259708, 0.01201579774259708, 0.02436393374259708, 0.00983359974259708, 0.008115665742597077, 0.00990358174259708, 0.00982054174259708, 0.00925827174259708, 0.006888406742597078, 0.007405122742597078, 0.014732905742597079, 0.023290073742597076, 0.008836825742597077, 0.008702456742597078, 0.006144041742597078, 0.013603075742597077, 0.012795273742597077, 0.010690248742597077, 0.01021836274259708, 0.010592865742597077, 0.01509301374259708, 0.01322288274259708, 0.00963778774259708, 0.011106529742597078, 0.007687046742597078, 0.011547737742597076, 0.017008993742597078, 0.009180634742597078, 0.009196559742597078, 0.011344054742597077, 0.015962370742597078, 0.008511965742597077, 0.010741740742597077, 0.014062314742597077, 0.010315440742597076, 0.01183362274259708, 0.007881105742597079, 0.013052758742597079, 0.013590942742597076, 0.015312180742597076, 0.01198805974259708, 0.014768408742597078, 0.010606200742597077, 0.017375668742597078, 0.010144936742597078, 0.01332342774259708, 0.010096368742597076, 0.012014519742597075, 0.015128965742597079, 0.007486616742597078, 0.013403893742597078, 0.009490146742597079, 0.010190953742597077, 0.020090891742597077, 0.00880753574259708, 0.008728962742597077, 0.008443432742597078, 0.012550509742597079, 0.011161788742597076, 0.009049594742597079, 0.017489733742597078, 0.008212257742597078, 0.013768147742597079, 0.01788225674259708, 0.0069019617425970774, 0.015214965742597078, 0.009526553742597078, 0.01150983774259708, 0.009839003742597077, 0.008069480742597078, 0.013081090742597078, 0.006931611742597077, 0.009535972742597078, 0.014239084742597077, 0.013108097742597077, 0.010338792742597077, 0.010651698742597079, 0.010622873742597079, 0.008845538742597078, 0.008799733742597078, 0.009216682742597078, 0.008988731742597077, 0.008080027742597078, 0.010553632742597078, 0.014132036742597075, 0.009941280742597078, 0.01293396674259708, 0.021403056742597078, 0.008392836742597078, 0.01257575374259708, 0.009723842742597077, 0.0077683727425970775, 0.012189141742597078, 0.008174769742597076, 0.009213343742597076, 0.010947052742597076, 0.019961014742597077, 0.008525551742597079, 0.016170897742597078, 0.012785151742597079, 0.012874919742597076, 0.005254250742597077, 0.005794816742597078, 0.011430979742597078, 0.010235369742597079, 0.014257861742597078, 0.013090711742597076, 0.01671332574259708, 0.009258104742597077, 0.007237852742597078, 0.010672597742597077, 0.007401876742597078, 0.009978195742597076, 0.012470654742597079, 0.014371888742597077, 0.02277682074259708, 0.008545177742597079, 0.01283096674259708, 0.011495896742597076, 0.013328133742597077, 0.009906205742597075, 0.01851528874259708, 0.008672800742597079, 0.014875653742597077, 0.012128884742597077, 0.012189795742597077, 0.02189241074259708, 0.01382822174259708, 0.011903510742597077, 0.018499097742597077, 0.008973062742597078, 0.009565996742597078, 0.008835710742597078, 0.011042721742597076, 0.009218792742597078, 0.013379503742597079, 0.013289433742597077, 0.01329123374259708, 0.010045688742597078, 0.02041340074259708, 0.017206263742597077, 0.00810693774259708, 0.009048518742597078, 0.00808704974259708, 0.00866173874259708, 0.012649737742597079, 0.01502862174259708, 0.008878940742597078, 0.009097353742597077, 0.008109871742597079, 0.011169509742597079, 0.0072610867425970775, 0.007577711742597078, 0.010732505742597077, 0.009311390742597077, 0.009403130742597077, 0.012256420742597078, 0.011147109742597076, 0.017572754742597077, 0.018281039742597077, 0.011494106742597078, 0.009424647742597079, 0.01699733874259708, 0.006237521742597078, 0.009155269742597078, 0.014507541742597076, 0.02125555874259708, 0.00978537574259708, 0.011469251742597077, 0.009034242742597079, 0.010445186742597076, 0.013917380742597078, 0.006264241742597077, 0.018238649742597077, 0.009750015742597078, 0.009749733742597078, 0.008398539742597078, 0.008509765742597077, 0.010289817742597077, 0.013295655742597078, 0.025158174742597076, 0.014525058742597078, 0.015219230742597078, 0.011437072742597077, 0.012836760742597077, 0.005419822742597078, 0.013626069742597079, 0.008842180742597077, 0.012132092742597078, 0.011693207742597078, 0.009063755742597077, 0.010472105742597076, 0.004839578742597079, 0.009309622742597078, 0.01926993474259708, 0.010405856742597079, 0.011140169742597076, 0.011119512742597079, 0.012279354742597077, 0.01076503574259708, 0.009468373742597078, 0.010887319742597077, 0.010046524742597079, 0.016152229742597075, 0.012044110742597078, 0.009998570742597076, 0.011907476742597078, 0.004042667742597078, 0.008069955742597078, 0.011505446742597077, 0.011789820742597077, 0.014674119742597077, 0.008409517742597076, 0.01406487374259708, 0.008483081742597078, 0.008142012742597078, 0.007776248742597078, 0.009007650742597077, 0.01263094374259708, 0.014535476742597076, 0.010047227742597076, 0.010663174742597079, 0.010430322742597076, 0.00981669174259708, 0.006654687742597078, 0.008794139742597077, 0.008905217742597078, 0.011778691742597078, 0.017248882742597078, 0.010663420742597077, 0.005630354742597077, 0.006221487742597077, 0.009249866742597077, 0.018564912742597077, 0.00802396274259708, 0.011020477742597078, 0.013083915742597079, 0.013959393742597078, 0.012384589742597079, 0.009731495742597077, 0.007534290742597078, 0.011049700742597077, 0.009927426742597077, 0.017987191742597077, 0.011164784742597078, 0.010410494742597077, 0.005703290742597078, 0.005396955742597078, 0.009662012742597077, 0.006396362742597078, 0.01060339574259708, 0.014011429742597076, 0.010733903742597077, 0.011319884742597076, 0.007950072742597077, 0.01268307574259708, 0.007335118742597078, 0.007644687742597078, 0.007989350742597077, 0.007730617742597077, 0.011901390742597079, 0.017971194742597077, 0.018172028742597077, 0.008399331742597077, 0.009802367742597077, 0.010058092742597077, 0.008553642742597078, 0.011679920742597077, 0.009089344742597077, 0.007083824742597079, 0.009758510742597077, 0.015274522742597076, 0.007507357742597078, 0.007189484742597078, 0.010399759742597079, 0.007345030742597078, 0.01841923674259708, 0.012705361742597078, 0.011161460742597079, 0.010977686742597078, 0.00924392874259708, 0.010591128742597078, 0.01620108374259708, 0.009179074742597076, 0.008679314742597078, 0.009205959742597077, 0.009891223742597079, 0.013076986742597078, 0.010553173742597078, 0.009130253742597079, 0.008804560742597077, 0.008019398742597078, 0.011065084742597077, 0.008397650742597077, 0.009034277742597078, 0.01046921974259708, 0.01647512374259708, 0.012643768742597077, 0.01814423074259708, 0.009744086742597077, 0.008919986742597079, 0.007093460742597078, 0.009345582742597077, 0.008701141742597077, 0.005739536742597078, 0.014437008742597077, 0.011545780742597076, 0.013082587742597077, 0.008697645742597078, 0.010102282742597078, 0.015024705742597077, 0.006778032742597077, 0.007978536742597079, 0.009787757742597079, 0.012086177742597078, 0.010918103742597076, 0.016045019742597078, 0.009594344742597079, 0.005776430742597078, 0.010071808742597079, 0.011381756742597077, 0.008296409742597079, 0.00839178674259708, 0.012590279742597077, 0.008306787742597077, 0.007338800742597078, 0.019885155742597076, 0.010681368742597078, 0.009127020742597077, 0.019853720742597076, 0.01446335974259708, 0.014022420742597078, 0.010441911742597077, 0.012762461742597077, 0.005296577742597077, 0.010630805742597078, 0.008124815742597078, 0.006048377742597077, 0.011132460742597078, 0.010784201742597078, 0.015035645742597078, 0.006837331742597079, 0.008590951742597077, 0.016550467742597077, 0.008526277742597076, 0.012549188742597077, 0.00836368774259708, 0.004634931742597077, 0.010752472742597077, 0.02044001674259708, 0.007405252742597078, 0.008408546742597077, 0.01769208574259708, 0.011673986742597078, 0.010139029742597078, 0.010277599742597078, 0.004476209742597077, 0.013681411742597079, 0.0061647527425970775, 0.009443382742597078, 0.013097893742597077, 0.013935873742597077, 0.007081532742597078, 0.010375221742597078, 0.015439913742597077, 0.006223566742597078, 0.01149865274259708, 0.008211913742597079, 0.014761195742597079, 0.010515486742597079, 0.009794987742597079, 0.008889290742597079, 0.007645996742597078, 0.02627482674259708, 0.011782890742597078, 0.009084496742597079, 0.015786648742597078, 0.023548216742597078, 0.009334118742597076, 0.02197807974259708, 0.012680642742597078, 0.011221191742597076, 0.019729419742597076, 0.009644047742597077, 0.008896905742597078, 0.014640971742597077, 0.015964689742597078, 0.008718282742597078, 0.008590151742597078, 0.01732189974259708, 0.011812034742597077, 0.008639837742597078, 0.0066784157425970785, 0.009942535742597078, 0.009939278742597077, 0.015779960742597077, 0.010409851742597079, 0.01504095474259708, 0.00991922974259708, 0.010341432742597079, 0.012313366742597077, 0.012620433742597078, 0.014845455742597078, 0.013500539742597076, 0.013269433742597078, 0.007598429742597078, 0.010528684742597078, 0.008744668742597078, 0.009763737742597079, 0.010275963742597077, 0.010701929742597078, 0.012224381742597079, 0.015958456742597077, 0.008547241742597078, 0.004657309742597078, 0.008300301742597077, 0.008641787742597079, 0.012051716742597078, 0.009376919742597078, 0.009228122742597078, 0.008961206742597077, 0.014355351742597076, 0.013780568742597078, 0.014750582742597076, 0.009757884742597077, 0.010902031742597077, 0.012056901742597076, 0.008823822742597078, 0.010119937742597077, 0.009336385742597078, 0.016632222742597076, 0.008973212742597079, 0.011356433742597077, 0.014009526742597077, 0.014425863742597078, 0.009266939742597078, 0.013481771742597078, 0.027727444742597078, 0.005956588742597077, 0.009103060742597077, 0.007513216742597078, 0.017719539742597077, 0.013934015742597079, 0.014639841742597078, 0.008648715742597079, 0.009307502742597076, 0.010877319742597077, 0.010230834742597079, 0.012300491742597078, 0.007358638742597077, 0.012887667742597076, 0.012927296742597077, 0.020449912742597078, 0.01164564774259708, 0.010175661742597077, 0.009203327742597078, 0.009011256742597078, 0.012895297742597078, 0.013198202742597078, 0.007482474742597078, 0.011001378742597077, 0.01127228874259708, 0.010664773742597077, 0.011302218742597077, 0.012979509742597078, 0.01484528874259708, 0.009048329742597078, 0.012374707742597078, 0.008487785742597079, 0.007953605742597077, 0.010147075742597078, 0.009492948742597079, 0.015375004742597079, 0.017884582742597077, 0.009934302742597077, 0.008900337742597079, 0.009475983742597078, 0.011684544742597076, 0.010547387742597078, 0.012156299742597078, 0.008944460742597079, 0.008612792742597079, 0.009364005742597077, 0.0060840207425970775, 0.010979989742597077, 0.006684613742597078, 0.00967693474259708, 0.01003403274259708, 0.010786988742597075, 0.012254845742597078, 0.01243029274259708, 0.020454426742597075, 0.009054848742597078, 0.008774826742597077, 0.01135801674259708, 0.011661892742597078, 0.008564070742597078, 0.008852028742597077, 0.014126812742597077, 0.014102728742597076, 0.015935609742597077, 0.008353761742597079, 0.008115290742597078, 0.009815444742597077, 0.008654576742597078, 0.01142091874259708, 0.008281752742597077, 0.014093491742597079, 0.008248111742597077, 0.008912836742597078, 0.010431960742597078, 0.013100149742597078, 0.005230716742597078, 0.005555079742597078, 0.008420199742597077, 0.016605791742597076, 0.012021475742597078, 0.009944525742597077, 0.008689293742597078, 0.008182266742597078, 0.008793439742597078, 0.009555137742597078, 0.013165207742597076, 0.017579508742597078, 0.009102011742597078, 0.00855036374259708, 0.008244972742597077, 0.012238368742597077, 0.0055780447425970775, 0.010318168742597077, 0.009902652742597077, 0.010040946742597078, 0.015318461742597078, 0.008167325742597077, 0.012756532742597079, 0.013827274742597078, 0.013296894742597078, 0.012349783742597077, 0.00037075974259707586, 0.009425025742597078, 0.006777272742597078, 0.0075735987425970775, 0.008254039742597079, 0.0060057867425970775, 0.010158048742597077, 0.011368663742597079, 0.005539654742597078, 0.01567213274259708, 0.008545554742597078, 0.01064638474259708, 0.010177393742597077, 0.015567887742597077, 0.009899818742597079, 0.009487037742597078, 0.007331118742597078, 0.009425115742597075, 0.014142067742597077, 0.0061653327425970775, 0.008712912742597077, 0.009307420742597078, 0.010689586742597079, 0.011991518742597077, 0.012523202742597078, 0.008050791742597076, 0.011665603742597078, 0.009319721742597077, 0.008043814742597077, 0.004051163742597078, 0.014017460742597077, 0.007929374742597077, 0.015303091742597079, 0.015628134742597076, 0.01941119774259708, 0.013413560742597076, 0.01735868674259708, 0.013277253742597077, 0.011508477742597077, 0.011527588742597078, 0.010821484742597077, 0.012115588742597078, 0.007597488742597076, 0.012973721742597078, 0.009864472742597077, 0.024665843742597077, 0.01552675774259708, 0.006618859742597078, 0.010645574742597077, 0.008201446742597079, 0.011153932742597078, 0.009343810742597079, 0.012035462742597078, 0.010499522742597078, 0.014142784742597076, 0.014442910742597077, 0.009736103742597077, 0.009396884742597079, 0.008982678742597078, 0.010927407742597078, 0.007571458742597078, 0.013275764742597077, 0.015263478742597078, 0.013131120742597077, 0.010587451742597077, 0.010745487742597077, 0.010027997742597078, 0.010533009742597077, 0.010448089742597078, 0.014705260742597079, 0.008151578742597077, 0.009877962742597078, 0.007482164742597078, 0.015684729742597076, 0.008901994742597077, 0.009456584742597078, 0.01298821374259708, 0.010214312742597077, 0.011708235742597078, 0.009267907742597076, 0.011918168742597077, 0.016580135742597077, 0.004981695742597078, 0.015402346742597078, 0.010701168742597078, 0.010662521742597079, 0.009182981742597077, 0.007214145742597078, 0.014448086742597078, 0.021133151742597077, 0.008855973742597077, 0.011179116742597077, 0.008771454742597079, 0.010977680742597078, 0.018684197742597077, 0.011178133742597077, 0.016489989742597078, 0.011373666742597079, 0.00937972474259708, 0.011851010742597076, 0.014744917742597077, 0.010352993742597079, 0.013427055742597078, 0.014691887742597078, 0.007288158742597077, 0.009072247742597078, 0.010696111742597079, 0.010877862742597078, 0.009730689742597078, 0.009924527742597077, 0.013336757742597077, 0.00814605774259708, 0.023951887742597076, 0.011419358742597079, 0.010466049742597076, 0.010479153742597079, 0.014930734742597079, 0.013558915742597077, 0.009172396742597077, 0.010839798742597079, 0.009686461742597078, 0.010917230742597078, 0.008416663742597079, 0.01796442774259708, 0.014118862742597077, 0.013346922742597078, 0.009261604742597077]\n"
     ]
    }
   ],
   "source": [
    "# initialize the output table\n",
    "CI_df = pd.DataFrame(index=range(0, predicted_test.shape[0]), columns=col_comp)\n",
    "\n",
    "# predicted parameter values from empirical set: here there is only one empirical set for which we want to compute CI values\n",
    "current_obs = predicted_test.iloc[0, :]\n",
    "current_obs_standardized = predicted_test_standardized.iloc[0, :]\n",
    "\n",
    "## find the 2% of closest simulations with respect to tree size and sampling frequency\n",
    "# first filter: keep only the closest 20k CI sets with respect to tree size\n",
    "tree_size_indexes = get_indexes_of_closest_single_factor(test_tree_size, CI_tree_size, 20000)\n",
    "filt_1_CI_predicted, filt_1_param_CI_standardized, filt_1_CI_param, filt_1_CI_sampling_proba = \\\n",
    "    apply_filter(CI_predicted, CI_param_standardized, CI_param, CI_sampling, tree_size_indexes)\n",
    "# reset indexes\n",
    "filt_1_CI_param.index = filt_1_param_CI_standardized.index = filt_1_CI_predicted.index = \\\n",
    "    filt_1_CI_sampling_proba.index = range(0, 20000)\n",
    "\n",
    "# second filter: keep only the closest 4k CI sets with respect to sampling frequency\n",
    "sampling_proba_indexes = get_indexes_of_closest_single_factor(samp_proba_list_test, filt_1_CI_sampling_proba, 4000)\n",
    "filt_2_CI_predicted, filt_2_param_CI_standardized, filt_2_CI_param, filt_2_CI_sampling_proba = \\\n",
    "    apply_filter(filt_1_CI_predicted, filt_1_param_CI_standardized, filt_1_CI_param,\n",
    "                 filt_1_CI_sampling_proba, sampling_proba_indexes)\n",
    "\n",
    "# reset indexes\n",
    "filt_2_CI_predicted.index = filt_2_param_CI_standardized.index = filt_2_CI_param.index = range(0, 4000)\n",
    "\n",
    "# vector to stock all measures of the current observation\n",
    "all_real = []\n",
    "\n",
    "for elt in targets:\n",
    "\n",
    "    # find indexes of closest parameter sets within the predicted values of 40K simulation of CI set\n",
    "    top_ind = get_indexes_of_closest_single_factor(current_obs_standardized[elt], filt_2_param_CI_standardized[\n",
    "        elt], n_neighbors[-1])\n",
    "\n",
    "    # measure errors on closest parameters sets (predicted - actual values)\n",
    "    pred_closest = get_predicted_closest_single(top_ind, filt_2_CI_predicted, elt)\n",
    "    error_closest = get_error_closest_single(top_ind, filt_2_CI_param, filt_2_CI_predicted, elt)\n",
    "\n",
    "    for j in range(len(n_neighbors)):\n",
    "        # refactor the measured error into a dict 'name_of_param': list of errors (top n neighbours)\n",
    "        pred_closest_n_neigh = pred_closest[0:n_neighbors[j]]\n",
    "        error_closest_n_neigh = error_closest[0:n_neighbors[j]]\n",
    "        median_pred = np.median(pred_closest_n_neigh)\n",
    "        median_error = np.median(error_closest_n_neigh)\n",
    "        # center the values around the given prediction\n",
    "        centered = [item - median_error + current_obs[elt] for item in error_closest_n_neigh]\n",
    "\n",
    "        # rescale back to original time scale of empirical observation for time-related parameters:\n",
    "        if 'resc' in elt:\n",
    "            centered_resc = [float(item) for item in centered]\n",
    "            current_obs[elt] = current_obs[elt]\n",
    "        else:\n",
    "            centered_resc = centered\n",
    "\n",
    "        # apply minimum and maximum values for each parameter (e.g. no negative values)\n",
    "        print(elt,centered_resc)\n",
    "        current_obs[elt] = max(min_max[elt][0], current_obs[elt])\n",
    "        current_obs[elt] = min(min_max[elt][1], current_obs[elt])\n",
    "        #centered_resc = [max(min_max[elt][0], item) for item in centered_resc]\n",
    "        #centered_resc = [min(min_max[elt][1], item) for item in centered_resc]\n",
    "        # compute statistics: 2.5%, 97.5% boundaries\n",
    "        qtls = np.percentile(centered_resc, np.array(np.array([2.5, 97.5])))\n",
    "        min_2_5 = qtls[0]\n",
    "        max_97_5 = qtls[1]\n",
    "        width_CI = qtls[1] - qtls[0]\n",
    "\n",
    "        all_real.append(min_2_5)\n",
    "        all_real.append(max_97_5)\n",
    "        all_real.append(width_CI)\n",
    "\n",
    "CI_df.loc[0, :] = all_real.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "executionInfo": {
     "elapsed": 235,
     "status": "ok",
     "timestamp": 1730645655337,
     "user": {
      "displayName": "Manolo Perez",
      "userId": "03028681885213161249"
     },
     "user_tz": 0
    },
    "id": "xbjZ7h1sl1du"
   },
   "outputs": [],
   "source": [
    "CI_df = pd.concat([current_obs.to_frame().T, CI_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 109
    },
    "executionInfo": {
     "elapsed": 231,
     "status": "ok",
     "timestamp": 1730645656432,
     "user": {
      "displayName": "Manolo Perez",
      "userId": "03028681885213161249"
     },
     "user_tz": 0
    },
    "id": "MdFDAjbvf74G",
    "outputId": "2c2d44a5-1727-44f2-dcbe-8a7805077386"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "summary": "{\n  \"name\": \"CI_df\",\n  \"rows\": 1,\n  \"fields\": [\n    {\n      \"column\": \"turnover\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.6104413270950317,\n        \"max\": 0.6104413270950317,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.6104413270950317\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"lambda1_rescaled\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.3782174291436144,\n        \"max\": 0.3782174291436144,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.3782174291436144\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"lambda2_rescaled\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.16615733231406066,\n        \"max\": 0.16615733231406066,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.16615733231406066\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"q01_rescaled\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.010635174242597079,\n        \"max\": 0.010635174242597079,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.010635174242597079\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"turnover_CI_2_5_1000\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": 0.39143526334503176,\n        \"max\": 0.39143526334503176,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.39143526334503176\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"turnover_CI_97_5_1000\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": 0.7337460580950317,\n        \"max\": 0.7337460580950317,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.7337460580950317\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"turnover_CI_width_1000\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": 0.3423107947499999,\n        \"max\": 0.3423107947499999,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.3423107947499999\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"lambda1_rescaled_CI_2_5_1000\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": 0.3102253414186144,\n        \"max\": 0.3102253414186144,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.3102253414186144\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"lambda1_rescaled_CI_97_5_1000\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": 0.44033470136861436,\n        \"max\": 0.44033470136861436,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.44033470136861436\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"lambda1_rescaled_CI_width_1000\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": 0.13010935994999995,\n        \"max\": 0.13010935994999995,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.13010935994999995\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"lambda2_rescaled_CI_2_5_1000\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": 0.10892012023906064,\n        \"max\": 0.10892012023906064,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.10892012023906064\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"lambda2_rescaled_CI_97_5_1000\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": 0.27592542183906066,\n        \"max\": 0.27592542183906066,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.27592542183906066\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"lambda2_rescaled_CI_width_1000\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": 0.16700530160000002,\n        \"max\": 0.16700530160000002,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.16700530160000002\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"q01_rescaled_CI_2_5_1000\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": 0.005794357092597078,\n        \"max\": 0.005794357092597078,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.005794357092597078\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"q01_rescaled_CI_97_5_1000\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": 0.02070666151759707,\n        \"max\": 0.02070666151759707,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.02070666151759707\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"q01_rescaled_CI_width_1000\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": 0.014912304424999991,\n        \"max\": 0.014912304424999991,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.014912304424999991\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
       "type": "dataframe",
       "variable_name": "CI_df"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-609310a2-a878-4a47-8cd9-c304d1a6669f\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>turnover</th>\n",
       "      <th>lambda1_rescaled</th>\n",
       "      <th>lambda2_rescaled</th>\n",
       "      <th>q01_rescaled</th>\n",
       "      <th>turnover_CI_2_5_1000</th>\n",
       "      <th>turnover_CI_97_5_1000</th>\n",
       "      <th>turnover_CI_width_1000</th>\n",
       "      <th>lambda1_rescaled_CI_2_5_1000</th>\n",
       "      <th>lambda1_rescaled_CI_97_5_1000</th>\n",
       "      <th>lambda1_rescaled_CI_width_1000</th>\n",
       "      <th>lambda2_rescaled_CI_2_5_1000</th>\n",
       "      <th>lambda2_rescaled_CI_97_5_1000</th>\n",
       "      <th>lambda2_rescaled_CI_width_1000</th>\n",
       "      <th>q01_rescaled_CI_2_5_1000</th>\n",
       "      <th>q01_rescaled_CI_97_5_1000</th>\n",
       "      <th>q01_rescaled_CI_width_1000</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.610441</td>\n",
       "      <td>0.378217</td>\n",
       "      <td>0.166157</td>\n",
       "      <td>0.010635</td>\n",
       "      <td>0.391435</td>\n",
       "      <td>0.733746</td>\n",
       "      <td>0.342311</td>\n",
       "      <td>0.310225</td>\n",
       "      <td>0.440335</td>\n",
       "      <td>0.130109</td>\n",
       "      <td>0.10892</td>\n",
       "      <td>0.275925</td>\n",
       "      <td>0.167005</td>\n",
       "      <td>0.005794</td>\n",
       "      <td>0.020707</td>\n",
       "      <td>0.014912</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-609310a2-a878-4a47-8cd9-c304d1a6669f')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-609310a2-a878-4a47-8cd9-c304d1a6669f button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-609310a2-a878-4a47-8cd9-c304d1a6669f');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "  <div id=\"id_95150bc2-155f-4def-9be7-2d01577812cf\">\n",
       "    <style>\n",
       "      .colab-df-generate {\n",
       "        background-color: #E8F0FE;\n",
       "        border: none;\n",
       "        border-radius: 50%;\n",
       "        cursor: pointer;\n",
       "        display: none;\n",
       "        fill: #1967D2;\n",
       "        height: 32px;\n",
       "        padding: 0 0 0 0;\n",
       "        width: 32px;\n",
       "      }\n",
       "\n",
       "      .colab-df-generate:hover {\n",
       "        background-color: #E2EBFA;\n",
       "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "        fill: #174EA6;\n",
       "      }\n",
       "\n",
       "      [theme=dark] .colab-df-generate {\n",
       "        background-color: #3B4455;\n",
       "        fill: #D2E3FC;\n",
       "      }\n",
       "\n",
       "      [theme=dark] .colab-df-generate:hover {\n",
       "        background-color: #434B5C;\n",
       "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "        fill: #FFFFFF;\n",
       "      }\n",
       "    </style>\n",
       "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('CI_df')\"\n",
       "            title=\"Generate code using this dataframe.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "    <script>\n",
       "      (() => {\n",
       "      const buttonEl =\n",
       "        document.querySelector('#id_95150bc2-155f-4def-9be7-2d01577812cf button.colab-df-generate');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      buttonEl.onclick = () => {\n",
       "        google.colab.notebook.generateWithVariable('CI_df');\n",
       "      }\n",
       "      })();\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "   turnover  lambda1_rescaled  lambda2_rescaled  q01_rescaled  \\\n",
       "0  0.610441          0.378217          0.166157      0.010635   \n",
       "\n",
       "  turnover_CI_2_5_1000 turnover_CI_97_5_1000 turnover_CI_width_1000  \\\n",
       "0             0.391435              0.733746               0.342311   \n",
       "\n",
       "  lambda1_rescaled_CI_2_5_1000 lambda1_rescaled_CI_97_5_1000  \\\n",
       "0                     0.310225                      0.440335   \n",
       "\n",
       "  lambda1_rescaled_CI_width_1000 lambda2_rescaled_CI_2_5_1000  \\\n",
       "0                       0.130109                      0.10892   \n",
       "\n",
       "  lambda2_rescaled_CI_97_5_1000 lambda2_rescaled_CI_width_1000  \\\n",
       "0                      0.275925                       0.167005   \n",
       "\n",
       "  q01_rescaled_CI_2_5_1000 q01_rescaled_CI_97_5_1000  \\\n",
       "0                 0.005794                  0.020707   \n",
       "\n",
       "  q01_rescaled_CI_width_1000  \n",
       "0                   0.014912  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#1000 trees\n",
    "CI_df"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "tensorflow-gpu-2.8.0_py3.9",
   "language": "python",
   "name": "module-conda-env-tensorflow-gpu-2.8.0_py3.9"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
